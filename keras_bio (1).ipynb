{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-bio.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Umy4hbZv1RG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "ea23e0f0-1f28-4ffc-b665-fefc0e03702b"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHCVNVAgyTIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1=pd.read_csv(\"column_2C_weka.csv\")\n",
        "data2=pd.read_csv(\"column_3C_weka.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie4J2nc9zMEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF3wlDiQzu-W",
        "colab_type": "code",
        "outputId": "15e0adb9-d7f0-436e-aa65-43603d5d5267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "data1.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 310 entries, 0 to 309\n",
            "Data columns (total 7 columns):\n",
            "pelvic_incidence            310 non-null float64\n",
            "pelvic_tilt numeric         310 non-null float64\n",
            "lumbar_lordosis_angle       310 non-null float64\n",
            "sacral_slope                310 non-null float64\n",
            "pelvic_radius               310 non-null float64\n",
            "degree_spondylolisthesis    310 non-null float64\n",
            "class                       310 non-null object\n",
            "dtypes: float64(6), object(1)\n",
            "memory usage: 17.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L2KAe-L2Qtg",
        "colab_type": "code",
        "outputId": "cc83a288-fe60-4265-ba41-08ed75b95b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data1.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(310, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-Z5UsbUzzsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing  import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnOWul5s0VKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lb=LabelEncoder()\n",
        "data1['class']=lb.fit_transform(data1['class'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEeMJrN_6p1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=data1.drop('class',axis=1)\n",
        "y=data1['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5g8HltnybM2",
        "colab_type": "code",
        "outputId": "19491150-da12-494c-ad0b-6095f8ed6e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sc=StandardScaler()\n",
        "sc.fit(x,y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN3qOL8Syhae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfG-3t3JykMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain_std=sc.fit_transform(xtrain)\n",
        "xtest_std=sc.fit_transform(xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugYqE4tAynZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZMSoyOoyrpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "1ee0d555-2414-452f-b81c-84e1d3f1041d"
      },
      "source": [
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(units=30,activation=\"relu\",input_shape=xtrain.shape[1:]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV0oYkKuyx9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(keras.layers.Dense(units=1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKTUHOQiy5hB",
        "colab_type": "code",
        "outputId": "ad7890ee-e6f9-4dfe-f191-0f01202d2abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT6EP92J2ADD",
        "colab_type": "code",
        "outputId": "1fab87a8-9e30-4d0d-b348-89480370c226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x=xtrain_std, y=ytrain, validation_split=0.1,epochs=100, batch_size=32)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 223 samples, validate on 25 samples\n",
            "Epoch 1/100\n",
            "223/223 [==============================] - 0s 1ms/sample - loss: 0.6744 - acc: 0.5874 - val_loss: 0.5772 - val_acc: 0.6800\n",
            "Epoch 2/100\n",
            "223/223 [==============================] - 0s 130us/sample - loss: 0.6471 - acc: 0.6009 - val_loss: 0.5563 - val_acc: 0.7200\n",
            "Epoch 3/100\n",
            "223/223 [==============================] - 0s 78us/sample - loss: 0.6244 - acc: 0.6502 - val_loss: 0.5363 - val_acc: 0.7600\n",
            "Epoch 4/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.6025 - acc: 0.6951 - val_loss: 0.5195 - val_acc: 0.8400\n",
            "Epoch 5/100\n",
            "223/223 [==============================] - 0s 85us/sample - loss: 0.5848 - acc: 0.6951 - val_loss: 0.5041 - val_acc: 0.8400\n",
            "Epoch 6/100\n",
            "223/223 [==============================] - 0s 112us/sample - loss: 0.5680 - acc: 0.6906 - val_loss: 0.4892 - val_acc: 0.8400\n",
            "Epoch 7/100\n",
            "223/223 [==============================] - 0s 82us/sample - loss: 0.5538 - acc: 0.7175 - val_loss: 0.4751 - val_acc: 0.8400\n",
            "Epoch 8/100\n",
            "223/223 [==============================] - 0s 81us/sample - loss: 0.5406 - acc: 0.7265 - val_loss: 0.4609 - val_acc: 0.9200\n",
            "Epoch 9/100\n",
            "223/223 [==============================] - 0s 84us/sample - loss: 0.5285 - acc: 0.7623 - val_loss: 0.4485 - val_acc: 0.9200\n",
            "Epoch 10/100\n",
            "223/223 [==============================] - 0s 91us/sample - loss: 0.5177 - acc: 0.7803 - val_loss: 0.4362 - val_acc: 0.9200\n",
            "Epoch 11/100\n",
            "223/223 [==============================] - 0s 80us/sample - loss: 0.5079 - acc: 0.7713 - val_loss: 0.4246 - val_acc: 0.9200\n",
            "Epoch 12/100\n",
            "223/223 [==============================] - 0s 90us/sample - loss: 0.4986 - acc: 0.7937 - val_loss: 0.4135 - val_acc: 0.9200\n",
            "Epoch 13/100\n",
            "223/223 [==============================] - 0s 99us/sample - loss: 0.4894 - acc: 0.7982 - val_loss: 0.4034 - val_acc: 0.9200\n",
            "Epoch 14/100\n",
            "223/223 [==============================] - 0s 89us/sample - loss: 0.4809 - acc: 0.7937 - val_loss: 0.3946 - val_acc: 0.9200\n",
            "Epoch 15/100\n",
            "223/223 [==============================] - 0s 79us/sample - loss: 0.4734 - acc: 0.7937 - val_loss: 0.3859 - val_acc: 0.9600\n",
            "Epoch 16/100\n",
            "223/223 [==============================] - 0s 81us/sample - loss: 0.4666 - acc: 0.7937 - val_loss: 0.3767 - val_acc: 0.9600\n",
            "Epoch 17/100\n",
            "223/223 [==============================] - 0s 78us/sample - loss: 0.4595 - acc: 0.7848 - val_loss: 0.3685 - val_acc: 0.9600\n",
            "Epoch 18/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.4530 - acc: 0.7892 - val_loss: 0.3621 - val_acc: 0.9600\n",
            "Epoch 19/100\n",
            "223/223 [==============================] - 0s 98us/sample - loss: 0.4471 - acc: 0.7937 - val_loss: 0.3550 - val_acc: 0.9600\n",
            "Epoch 20/100\n",
            "223/223 [==============================] - 0s 81us/sample - loss: 0.4414 - acc: 0.8072 - val_loss: 0.3483 - val_acc: 0.9600\n",
            "Epoch 21/100\n",
            "223/223 [==============================] - 0s 88us/sample - loss: 0.4356 - acc: 0.8206 - val_loss: 0.3418 - val_acc: 0.9600\n",
            "Epoch 22/100\n",
            "223/223 [==============================] - 0s 68us/sample - loss: 0.4302 - acc: 0.8251 - val_loss: 0.3358 - val_acc: 0.9600\n",
            "Epoch 23/100\n",
            "223/223 [==============================] - 0s 88us/sample - loss: 0.4253 - acc: 0.8251 - val_loss: 0.3299 - val_acc: 0.9600\n",
            "Epoch 24/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.4204 - acc: 0.8251 - val_loss: 0.3243 - val_acc: 0.9600\n",
            "Epoch 25/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.4156 - acc: 0.8296 - val_loss: 0.3205 - val_acc: 0.9600\n",
            "Epoch 26/100\n",
            "223/223 [==============================] - 0s 70us/sample - loss: 0.4109 - acc: 0.8341 - val_loss: 0.3160 - val_acc: 0.9600\n",
            "Epoch 27/100\n",
            "223/223 [==============================] - 0s 79us/sample - loss: 0.4071 - acc: 0.8341 - val_loss: 0.3116 - val_acc: 0.9600\n",
            "Epoch 28/100\n",
            "223/223 [==============================] - 0s 76us/sample - loss: 0.4026 - acc: 0.8341 - val_loss: 0.3072 - val_acc: 0.9600\n",
            "Epoch 29/100\n",
            "223/223 [==============================] - 0s 80us/sample - loss: 0.3991 - acc: 0.8341 - val_loss: 0.3023 - val_acc: 0.9600\n",
            "Epoch 30/100\n",
            "223/223 [==============================] - 0s 77us/sample - loss: 0.3948 - acc: 0.8341 - val_loss: 0.2995 - val_acc: 0.9600\n",
            "Epoch 31/100\n",
            "223/223 [==============================] - 0s 90us/sample - loss: 0.3908 - acc: 0.8341 - val_loss: 0.2961 - val_acc: 0.9600\n",
            "Epoch 32/100\n",
            "223/223 [==============================] - 0s 92us/sample - loss: 0.3872 - acc: 0.8386 - val_loss: 0.2924 - val_acc: 0.9600\n",
            "Epoch 33/100\n",
            "223/223 [==============================] - 0s 75us/sample - loss: 0.3838 - acc: 0.8386 - val_loss: 0.2897 - val_acc: 0.9600\n",
            "Epoch 34/100\n",
            "223/223 [==============================] - 0s 78us/sample - loss: 0.3803 - acc: 0.8386 - val_loss: 0.2872 - val_acc: 0.9600\n",
            "Epoch 35/100\n",
            "223/223 [==============================] - 0s 79us/sample - loss: 0.3771 - acc: 0.8386 - val_loss: 0.2837 - val_acc: 0.9600\n",
            "Epoch 36/100\n",
            "223/223 [==============================] - 0s 80us/sample - loss: 0.3737 - acc: 0.8341 - val_loss: 0.2812 - val_acc: 0.9600\n",
            "Epoch 37/100\n",
            "223/223 [==============================] - 0s 82us/sample - loss: 0.3710 - acc: 0.8341 - val_loss: 0.2785 - val_acc: 0.9200\n",
            "Epoch 38/100\n",
            "223/223 [==============================] - 0s 84us/sample - loss: 0.3681 - acc: 0.8341 - val_loss: 0.2772 - val_acc: 0.9200\n",
            "Epoch 39/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.3648 - acc: 0.8341 - val_loss: 0.2753 - val_acc: 0.9200\n",
            "Epoch 40/100\n",
            "223/223 [==============================] - 0s 71us/sample - loss: 0.3619 - acc: 0.8341 - val_loss: 0.2735 - val_acc: 0.9200\n",
            "Epoch 41/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.3589 - acc: 0.8341 - val_loss: 0.2708 - val_acc: 0.9200\n",
            "Epoch 42/100\n",
            "223/223 [==============================] - 0s 69us/sample - loss: 0.3566 - acc: 0.8341 - val_loss: 0.2686 - val_acc: 0.9200\n",
            "Epoch 43/100\n",
            "223/223 [==============================] - 0s 71us/sample - loss: 0.3536 - acc: 0.8341 - val_loss: 0.2671 - val_acc: 0.9200\n",
            "Epoch 44/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.3511 - acc: 0.8341 - val_loss: 0.2656 - val_acc: 0.9200\n",
            "Epoch 45/100\n",
            "223/223 [==============================] - 0s 81us/sample - loss: 0.3485 - acc: 0.8341 - val_loss: 0.2636 - val_acc: 0.9200\n",
            "Epoch 46/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.3464 - acc: 0.8341 - val_loss: 0.2623 - val_acc: 0.9200\n",
            "Epoch 47/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.3440 - acc: 0.8341 - val_loss: 0.2609 - val_acc: 0.9200\n",
            "Epoch 48/100\n",
            "223/223 [==============================] - 0s 77us/sample - loss: 0.3417 - acc: 0.8341 - val_loss: 0.2596 - val_acc: 0.9200\n",
            "Epoch 49/100\n",
            "223/223 [==============================] - 0s 74us/sample - loss: 0.3396 - acc: 0.8341 - val_loss: 0.2583 - val_acc: 0.9200\n",
            "Epoch 50/100\n",
            "223/223 [==============================] - 0s 81us/sample - loss: 0.3374 - acc: 0.8386 - val_loss: 0.2572 - val_acc: 0.9200\n",
            "Epoch 51/100\n",
            "223/223 [==============================] - 0s 75us/sample - loss: 0.3352 - acc: 0.8386 - val_loss: 0.2559 - val_acc: 0.9200\n",
            "Epoch 52/100\n",
            "223/223 [==============================] - 0s 85us/sample - loss: 0.3333 - acc: 0.8341 - val_loss: 0.2548 - val_acc: 0.9200\n",
            "Epoch 53/100\n",
            "223/223 [==============================] - 0s 99us/sample - loss: 0.3313 - acc: 0.8341 - val_loss: 0.2534 - val_acc: 0.9200\n",
            "Epoch 54/100\n",
            "223/223 [==============================] - 0s 65us/sample - loss: 0.3294 - acc: 0.8386 - val_loss: 0.2520 - val_acc: 0.9200\n",
            "Epoch 55/100\n",
            "223/223 [==============================] - 0s 71us/sample - loss: 0.3276 - acc: 0.8386 - val_loss: 0.2513 - val_acc: 0.9200\n",
            "Epoch 56/100\n",
            "223/223 [==============================] - 0s 80us/sample - loss: 0.3268 - acc: 0.8386 - val_loss: 0.2498 - val_acc: 0.9200\n",
            "Epoch 57/100\n",
            "223/223 [==============================] - 0s 82us/sample - loss: 0.3241 - acc: 0.8341 - val_loss: 0.2491 - val_acc: 0.9200\n",
            "Epoch 58/100\n",
            "223/223 [==============================] - 0s 80us/sample - loss: 0.3227 - acc: 0.8296 - val_loss: 0.2489 - val_acc: 0.9200\n",
            "Epoch 59/100\n",
            "223/223 [==============================] - 0s 115us/sample - loss: 0.3208 - acc: 0.8296 - val_loss: 0.2483 - val_acc: 0.9200\n",
            "Epoch 60/100\n",
            "223/223 [==============================] - 0s 65us/sample - loss: 0.3192 - acc: 0.8251 - val_loss: 0.2476 - val_acc: 0.9200\n",
            "Epoch 61/100\n",
            "223/223 [==============================] - 0s 98us/sample - loss: 0.3177 - acc: 0.8296 - val_loss: 0.2471 - val_acc: 0.9200\n",
            "Epoch 62/100\n",
            "223/223 [==============================] - 0s 70us/sample - loss: 0.3167 - acc: 0.8296 - val_loss: 0.2460 - val_acc: 0.9200\n",
            "Epoch 63/100\n",
            "223/223 [==============================] - 0s 64us/sample - loss: 0.3150 - acc: 0.8296 - val_loss: 0.2458 - val_acc: 0.9200\n",
            "Epoch 64/100\n",
            "223/223 [==============================] - 0s 71us/sample - loss: 0.3135 - acc: 0.8341 - val_loss: 0.2445 - val_acc: 0.9200\n",
            "Epoch 65/100\n",
            "223/223 [==============================] - 0s 72us/sample - loss: 0.3121 - acc: 0.8386 - val_loss: 0.2436 - val_acc: 0.9200\n",
            "Epoch 66/100\n",
            "223/223 [==============================] - 0s 62us/sample - loss: 0.3114 - acc: 0.8430 - val_loss: 0.2421 - val_acc: 0.9200\n",
            "Epoch 67/100\n",
            "223/223 [==============================] - 0s 75us/sample - loss: 0.3101 - acc: 0.8386 - val_loss: 0.2428 - val_acc: 0.9200\n",
            "Epoch 68/100\n",
            "223/223 [==============================] - 0s 70us/sample - loss: 0.3083 - acc: 0.8386 - val_loss: 0.2423 - val_acc: 0.9200\n",
            "Epoch 69/100\n",
            "223/223 [==============================] - 0s 71us/sample - loss: 0.3071 - acc: 0.8341 - val_loss: 0.2416 - val_acc: 0.9200\n",
            "Epoch 70/100\n",
            "223/223 [==============================] - 0s 72us/sample - loss: 0.3058 - acc: 0.8341 - val_loss: 0.2407 - val_acc: 0.9200\n",
            "Epoch 71/100\n",
            "223/223 [==============================] - 0s 73us/sample - loss: 0.3048 - acc: 0.8341 - val_loss: 0.2407 - val_acc: 0.9200\n",
            "Epoch 72/100\n",
            "223/223 [==============================] - 0s 80us/sample - loss: 0.3038 - acc: 0.8386 - val_loss: 0.2401 - val_acc: 0.9200\n",
            "Epoch 73/100\n",
            "223/223 [==============================] - 0s 75us/sample - loss: 0.3027 - acc: 0.8386 - val_loss: 0.2389 - val_acc: 0.9200\n",
            "Epoch 74/100\n",
            "223/223 [==============================] - 0s 71us/sample - loss: 0.3020 - acc: 0.8386 - val_loss: 0.2382 - val_acc: 0.9200\n",
            "Epoch 75/100\n",
            "223/223 [==============================] - 0s 74us/sample - loss: 0.3006 - acc: 0.8386 - val_loss: 0.2383 - val_acc: 0.9200\n",
            "Epoch 76/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.2994 - acc: 0.8386 - val_loss: 0.2380 - val_acc: 0.9200\n",
            "Epoch 77/100\n",
            "223/223 [==============================] - 0s 74us/sample - loss: 0.2986 - acc: 0.8430 - val_loss: 0.2383 - val_acc: 0.9200\n",
            "Epoch 78/100\n",
            "223/223 [==============================] - 0s 68us/sample - loss: 0.2975 - acc: 0.8475 - val_loss: 0.2380 - val_acc: 0.9200\n",
            "Epoch 79/100\n",
            "223/223 [==============================] - 0s 84us/sample - loss: 0.2973 - acc: 0.8475 - val_loss: 0.2380 - val_acc: 0.9200\n",
            "Epoch 80/100\n",
            "223/223 [==============================] - 0s 114us/sample - loss: 0.2960 - acc: 0.8475 - val_loss: 0.2376 - val_acc: 0.9200\n",
            "Epoch 81/100\n",
            "223/223 [==============================] - 0s 100us/sample - loss: 0.2949 - acc: 0.8475 - val_loss: 0.2370 - val_acc: 0.9200\n",
            "Epoch 82/100\n",
            "223/223 [==============================] - 0s 76us/sample - loss: 0.2942 - acc: 0.8430 - val_loss: 0.2368 - val_acc: 0.9200\n",
            "Epoch 83/100\n",
            "223/223 [==============================] - 0s 95us/sample - loss: 0.2932 - acc: 0.8475 - val_loss: 0.2359 - val_acc: 0.9200\n",
            "Epoch 84/100\n",
            "223/223 [==============================] - 0s 77us/sample - loss: 0.2925 - acc: 0.8430 - val_loss: 0.2356 - val_acc: 0.9200\n",
            "Epoch 85/100\n",
            "223/223 [==============================] - 0s 71us/sample - loss: 0.2919 - acc: 0.8430 - val_loss: 0.2355 - val_acc: 0.9200\n",
            "Epoch 86/100\n",
            "223/223 [==============================] - 0s 85us/sample - loss: 0.2910 - acc: 0.8475 - val_loss: 0.2356 - val_acc: 0.9200\n",
            "Epoch 87/100\n",
            "223/223 [==============================] - 0s 80us/sample - loss: 0.2905 - acc: 0.8475 - val_loss: 0.2356 - val_acc: 0.9200\n",
            "Epoch 88/100\n",
            "223/223 [==============================] - 0s 80us/sample - loss: 0.2897 - acc: 0.8475 - val_loss: 0.2356 - val_acc: 0.9200\n",
            "Epoch 89/100\n",
            "223/223 [==============================] - 0s 92us/sample - loss: 0.2892 - acc: 0.8475 - val_loss: 0.2350 - val_acc: 0.9200\n",
            "Epoch 90/100\n",
            "223/223 [==============================] - 0s 88us/sample - loss: 0.2884 - acc: 0.8475 - val_loss: 0.2349 - val_acc: 0.9200\n",
            "Epoch 91/100\n",
            "223/223 [==============================] - 0s 84us/sample - loss: 0.2876 - acc: 0.8430 - val_loss: 0.2344 - val_acc: 0.9200\n",
            "Epoch 92/100\n",
            "223/223 [==============================] - 0s 85us/sample - loss: 0.2870 - acc: 0.8430 - val_loss: 0.2343 - val_acc: 0.9200\n",
            "Epoch 93/100\n",
            "223/223 [==============================] - 0s 87us/sample - loss: 0.2864 - acc: 0.8520 - val_loss: 0.2343 - val_acc: 0.9200\n",
            "Epoch 94/100\n",
            "223/223 [==============================] - 0s 87us/sample - loss: 0.2858 - acc: 0.8520 - val_loss: 0.2338 - val_acc: 0.9200\n",
            "Epoch 95/100\n",
            "223/223 [==============================] - 0s 79us/sample - loss: 0.2853 - acc: 0.8475 - val_loss: 0.2336 - val_acc: 0.9200\n",
            "Epoch 96/100\n",
            "223/223 [==============================] - 0s 85us/sample - loss: 0.2848 - acc: 0.8520 - val_loss: 0.2340 - val_acc: 0.9200\n",
            "Epoch 97/100\n",
            "223/223 [==============================] - 0s 87us/sample - loss: 0.2840 - acc: 0.8520 - val_loss: 0.2338 - val_acc: 0.9200\n",
            "Epoch 98/100\n",
            "223/223 [==============================] - 0s 87us/sample - loss: 0.2835 - acc: 0.8520 - val_loss: 0.2336 - val_acc: 0.9200\n",
            "Epoch 99/100\n",
            "223/223 [==============================] - 0s 69us/sample - loss: 0.2832 - acc: 0.8475 - val_loss: 0.2330 - val_acc: 0.9200\n",
            "Epoch 100/100\n",
            "223/223 [==============================] - 0s 87us/sample - loss: 0.2825 - acc: 0.8520 - val_loss: 0.2336 - val_acc: 0.9200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd58f210cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqi-mDLIzSQa",
        "colab_type": "code",
        "outputId": "e593b72b-6b87-4056-bb42-ef71fe134a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(x=xtest_std, y=ytest)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 112us/sample - loss: 0.2556 - acc: 0.8871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASG34RZ1zWb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8e84adc-8789-4c26-a101-797d0de7079f"
      },
      "source": [
        "print('test accuracy=',test_accuracy,'test loss=',test_loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy= 0.88709676 test loss= 0.2555874345764037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE5LlsdD6nRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lb=LabelEncoder()\n",
        "data2['class']=lb.fit_transform(data2['class'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnclOmp77C0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=data2.drop('class',axis=1)\n",
        "y=data2['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-l9jcvC7ONR",
        "colab_type": "code",
        "outputId": "7d809ace-a7ed-4f6c-8264-c57e9783aa9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sc.fit(x,y)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_3ZUgiy6rVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0L24dLY7U0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain_std=sc.fit_transform(xtrain)\n",
        "xtest_std=sc.fit_transform(xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKs_V3ad6zj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(units=50,activation=\"relu\",input_shape=xtrain.shape[1:]))\n",
        "model.add(keras.layers.Dense(units=3,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bnEdumw7DUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO0HKYN77G7l",
        "colab_type": "code",
        "outputId": "bf81f426-5782-4fe3-fa5d-904d65d5da82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x=xtrain_std, y=ytrain, validation_split=0.1,epochs=100, batch_size=32)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 223 samples, validate on 25 samples\n",
            "Epoch 1/100\n",
            "223/223 [==============================] - 0s 1ms/sample - loss: 1.0993 - acc: 0.3004 - val_loss: 1.0427 - val_acc: 0.2800\n",
            "Epoch 2/100\n",
            "223/223 [==============================] - 0s 84us/sample - loss: 1.0122 - acc: 0.4933 - val_loss: 0.9747 - val_acc: 0.6400\n",
            "Epoch 3/100\n",
            "223/223 [==============================] - 0s 93us/sample - loss: 0.9316 - acc: 0.6682 - val_loss: 0.9152 - val_acc: 0.6800\n",
            "Epoch 4/100\n",
            "223/223 [==============================] - 0s 102us/sample - loss: 0.8623 - acc: 0.7758 - val_loss: 0.8615 - val_acc: 0.8800\n",
            "Epoch 5/100\n",
            "223/223 [==============================] - 0s 90us/sample - loss: 0.8032 - acc: 0.7937 - val_loss: 0.8150 - val_acc: 0.8400\n",
            "Epoch 6/100\n",
            "223/223 [==============================] - 0s 93us/sample - loss: 0.7501 - acc: 0.8117 - val_loss: 0.7750 - val_acc: 0.8400\n",
            "Epoch 7/100\n",
            "223/223 [==============================] - 0s 94us/sample - loss: 0.7074 - acc: 0.8161 - val_loss: 0.7411 - val_acc: 0.7600\n",
            "Epoch 8/100\n",
            "223/223 [==============================] - 0s 79us/sample - loss: 0.6695 - acc: 0.8341 - val_loss: 0.7124 - val_acc: 0.7600\n",
            "Epoch 9/100\n",
            "223/223 [==============================] - 0s 78us/sample - loss: 0.6383 - acc: 0.8386 - val_loss: 0.6872 - val_acc: 0.7600\n",
            "Epoch 10/100\n",
            "223/223 [==============================] - 0s 73us/sample - loss: 0.6124 - acc: 0.8296 - val_loss: 0.6645 - val_acc: 0.7600\n",
            "Epoch 11/100\n",
            "223/223 [==============================] - 0s 87us/sample - loss: 0.5895 - acc: 0.8251 - val_loss: 0.6454 - val_acc: 0.7200\n",
            "Epoch 12/100\n",
            "223/223 [==============================] - 0s 99us/sample - loss: 0.5706 - acc: 0.8296 - val_loss: 0.6244 - val_acc: 0.7600\n",
            "Epoch 13/100\n",
            "223/223 [==============================] - 0s 91us/sample - loss: 0.5541 - acc: 0.8341 - val_loss: 0.6072 - val_acc: 0.7600\n",
            "Epoch 14/100\n",
            "223/223 [==============================] - 0s 92us/sample - loss: 0.5392 - acc: 0.8296 - val_loss: 0.5916 - val_acc: 0.7600\n",
            "Epoch 15/100\n",
            "223/223 [==============================] - 0s 115us/sample - loss: 0.5262 - acc: 0.8296 - val_loss: 0.5750 - val_acc: 0.7600\n",
            "Epoch 16/100\n",
            "223/223 [==============================] - 0s 93us/sample - loss: 0.5146 - acc: 0.8341 - val_loss: 0.5607 - val_acc: 0.7600\n",
            "Epoch 17/100\n",
            "223/223 [==============================] - 0s 81us/sample - loss: 0.5037 - acc: 0.8341 - val_loss: 0.5504 - val_acc: 0.7600\n",
            "Epoch 18/100\n",
            "223/223 [==============================] - 0s 81us/sample - loss: 0.4937 - acc: 0.8341 - val_loss: 0.5379 - val_acc: 0.7600\n",
            "Epoch 19/100\n",
            "223/223 [==============================] - 0s 88us/sample - loss: 0.4849 - acc: 0.8296 - val_loss: 0.5260 - val_acc: 0.7600\n",
            "Epoch 20/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.4762 - acc: 0.8341 - val_loss: 0.5168 - val_acc: 0.7600\n",
            "Epoch 21/100\n",
            "223/223 [==============================] - 0s 109us/sample - loss: 0.4687 - acc: 0.8341 - val_loss: 0.5040 - val_acc: 0.7600\n",
            "Epoch 22/100\n",
            "223/223 [==============================] - 0s 91us/sample - loss: 0.4610 - acc: 0.8341 - val_loss: 0.4950 - val_acc: 0.7600\n",
            "Epoch 23/100\n",
            "223/223 [==============================] - 0s 104us/sample - loss: 0.4541 - acc: 0.8341 - val_loss: 0.4892 - val_acc: 0.7600\n",
            "Epoch 24/100\n",
            "223/223 [==============================] - 0s 99us/sample - loss: 0.4473 - acc: 0.8296 - val_loss: 0.4836 - val_acc: 0.7600\n",
            "Epoch 25/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.4405 - acc: 0.8296 - val_loss: 0.4750 - val_acc: 0.7600\n",
            "Epoch 26/100\n",
            "223/223 [==============================] - 0s 110us/sample - loss: 0.4346 - acc: 0.8251 - val_loss: 0.4695 - val_acc: 0.7600\n",
            "Epoch 27/100\n",
            "223/223 [==============================] - 0s 95us/sample - loss: 0.4282 - acc: 0.8251 - val_loss: 0.4638 - val_acc: 0.7600\n",
            "Epoch 28/100\n",
            "223/223 [==============================] - 0s 95us/sample - loss: 0.4231 - acc: 0.8251 - val_loss: 0.4590 - val_acc: 0.7600\n",
            "Epoch 29/100\n",
            "223/223 [==============================] - 0s 108us/sample - loss: 0.4173 - acc: 0.8251 - val_loss: 0.4520 - val_acc: 0.7600\n",
            "Epoch 30/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.4117 - acc: 0.8251 - val_loss: 0.4458 - val_acc: 0.8000\n",
            "Epoch 31/100\n",
            "223/223 [==============================] - 0s 88us/sample - loss: 0.4067 - acc: 0.8296 - val_loss: 0.4412 - val_acc: 0.8000\n",
            "Epoch 32/100\n",
            "223/223 [==============================] - 0s 76us/sample - loss: 0.4017 - acc: 0.8341 - val_loss: 0.4351 - val_acc: 0.8000\n",
            "Epoch 33/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.3972 - acc: 0.8341 - val_loss: 0.4311 - val_acc: 0.8000\n",
            "Epoch 34/100\n",
            "223/223 [==============================] - 0s 101us/sample - loss: 0.3919 - acc: 0.8430 - val_loss: 0.4273 - val_acc: 0.8000\n",
            "Epoch 35/100\n",
            "223/223 [==============================] - 0s 96us/sample - loss: 0.3876 - acc: 0.8386 - val_loss: 0.4259 - val_acc: 0.8000\n",
            "Epoch 36/100\n",
            "223/223 [==============================] - 0s 94us/sample - loss: 0.3837 - acc: 0.8386 - val_loss: 0.4232 - val_acc: 0.8000\n",
            "Epoch 37/100\n",
            "223/223 [==============================] - 0s 82us/sample - loss: 0.3790 - acc: 0.8386 - val_loss: 0.4177 - val_acc: 0.8000\n",
            "Epoch 38/100\n",
            "223/223 [==============================] - 0s 89us/sample - loss: 0.3753 - acc: 0.8341 - val_loss: 0.4109 - val_acc: 0.8000\n",
            "Epoch 39/100\n",
            "223/223 [==============================] - 0s 76us/sample - loss: 0.3712 - acc: 0.8386 - val_loss: 0.4084 - val_acc: 0.8000\n",
            "Epoch 40/100\n",
            "223/223 [==============================] - 0s 77us/sample - loss: 0.3674 - acc: 0.8430 - val_loss: 0.4089 - val_acc: 0.8000\n",
            "Epoch 41/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.3638 - acc: 0.8430 - val_loss: 0.4030 - val_acc: 0.8000\n",
            "Epoch 42/100\n",
            "223/223 [==============================] - 0s 82us/sample - loss: 0.3601 - acc: 0.8430 - val_loss: 0.4012 - val_acc: 0.8000\n",
            "Epoch 43/100\n",
            "223/223 [==============================] - 0s 96us/sample - loss: 0.3565 - acc: 0.8430 - val_loss: 0.3981 - val_acc: 0.8000\n",
            "Epoch 44/100\n",
            "223/223 [==============================] - 0s 87us/sample - loss: 0.3534 - acc: 0.8430 - val_loss: 0.3933 - val_acc: 0.8000\n",
            "Epoch 45/100\n",
            "223/223 [==============================] - 0s 142us/sample - loss: 0.3498 - acc: 0.8430 - val_loss: 0.3883 - val_acc: 0.8000\n",
            "Epoch 46/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.3468 - acc: 0.8430 - val_loss: 0.3880 - val_acc: 0.8000\n",
            "Epoch 47/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.3437 - acc: 0.8475 - val_loss: 0.3867 - val_acc: 0.8000\n",
            "Epoch 48/100\n",
            "223/223 [==============================] - 0s 93us/sample - loss: 0.3410 - acc: 0.8520 - val_loss: 0.3843 - val_acc: 0.8000\n",
            "Epoch 49/100\n",
            "223/223 [==============================] - 0s 89us/sample - loss: 0.3380 - acc: 0.8520 - val_loss: 0.3776 - val_acc: 0.8000\n",
            "Epoch 50/100\n",
            "223/223 [==============================] - 0s 92us/sample - loss: 0.3352 - acc: 0.8520 - val_loss: 0.3750 - val_acc: 0.8000\n",
            "Epoch 51/100\n",
            "223/223 [==============================] - 0s 99us/sample - loss: 0.3323 - acc: 0.8565 - val_loss: 0.3772 - val_acc: 0.8000\n",
            "Epoch 52/100\n",
            "223/223 [==============================] - 0s 120us/sample - loss: 0.3298 - acc: 0.8565 - val_loss: 0.3736 - val_acc: 0.8000\n",
            "Epoch 53/100\n",
            "223/223 [==============================] - 0s 80us/sample - loss: 0.3274 - acc: 0.8565 - val_loss: 0.3734 - val_acc: 0.8000\n",
            "Epoch 54/100\n",
            "223/223 [==============================] - 0s 115us/sample - loss: 0.3246 - acc: 0.8565 - val_loss: 0.3676 - val_acc: 0.8000\n",
            "Epoch 55/100\n",
            "223/223 [==============================] - 0s 87us/sample - loss: 0.3222 - acc: 0.8565 - val_loss: 0.3659 - val_acc: 0.8000\n",
            "Epoch 56/100\n",
            "223/223 [==============================] - 0s 96us/sample - loss: 0.3198 - acc: 0.8565 - val_loss: 0.3630 - val_acc: 0.8000\n",
            "Epoch 57/100\n",
            "223/223 [==============================] - 0s 85us/sample - loss: 0.3174 - acc: 0.8565 - val_loss: 0.3635 - val_acc: 0.8000\n",
            "Epoch 58/100\n",
            "223/223 [==============================] - 0s 89us/sample - loss: 0.3155 - acc: 0.8565 - val_loss: 0.3592 - val_acc: 0.8000\n",
            "Epoch 59/100\n",
            "223/223 [==============================] - 0s 82us/sample - loss: 0.3134 - acc: 0.8565 - val_loss: 0.3580 - val_acc: 0.8000\n",
            "Epoch 60/100\n",
            "223/223 [==============================] - 0s 98us/sample - loss: 0.3113 - acc: 0.8565 - val_loss: 0.3554 - val_acc: 0.8000\n",
            "Epoch 61/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.3090 - acc: 0.8610 - val_loss: 0.3543 - val_acc: 0.8000\n",
            "Epoch 62/100\n",
            "223/223 [==============================] - 0s 98us/sample - loss: 0.3074 - acc: 0.8610 - val_loss: 0.3558 - val_acc: 0.8000\n",
            "Epoch 63/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.3052 - acc: 0.8655 - val_loss: 0.3532 - val_acc: 0.8000\n",
            "Epoch 64/100\n",
            "223/223 [==============================] - 0s 81us/sample - loss: 0.3033 - acc: 0.8700 - val_loss: 0.3505 - val_acc: 0.8000\n",
            "Epoch 65/100\n",
            "223/223 [==============================] - 0s 74us/sample - loss: 0.3019 - acc: 0.8700 - val_loss: 0.3484 - val_acc: 0.8000\n",
            "Epoch 66/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.3000 - acc: 0.8744 - val_loss: 0.3461 - val_acc: 0.8000\n",
            "Epoch 67/100\n",
            "223/223 [==============================] - 0s 110us/sample - loss: 0.2982 - acc: 0.8744 - val_loss: 0.3451 - val_acc: 0.8000\n",
            "Epoch 68/100\n",
            "223/223 [==============================] - 0s 99us/sample - loss: 0.2967 - acc: 0.8744 - val_loss: 0.3438 - val_acc: 0.8000\n",
            "Epoch 69/100\n",
            "223/223 [==============================] - 0s 81us/sample - loss: 0.2953 - acc: 0.8744 - val_loss: 0.3410 - val_acc: 0.8000\n",
            "Epoch 70/100\n",
            "223/223 [==============================] - 0s 94us/sample - loss: 0.2940 - acc: 0.8744 - val_loss: 0.3387 - val_acc: 0.8000\n",
            "Epoch 71/100\n",
            "223/223 [==============================] - 0s 70us/sample - loss: 0.2922 - acc: 0.8744 - val_loss: 0.3399 - val_acc: 0.8000\n",
            "Epoch 72/100\n",
            "223/223 [==============================] - 0s 85us/sample - loss: 0.2909 - acc: 0.8744 - val_loss: 0.3418 - val_acc: 0.8000\n",
            "Epoch 73/100\n",
            "223/223 [==============================] - 0s 82us/sample - loss: 0.2896 - acc: 0.8744 - val_loss: 0.3377 - val_acc: 0.8000\n",
            "Epoch 74/100\n",
            "223/223 [==============================] - 0s 71us/sample - loss: 0.2886 - acc: 0.8744 - val_loss: 0.3339 - val_acc: 0.8000\n",
            "Epoch 75/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.2870 - acc: 0.8744 - val_loss: 0.3335 - val_acc: 0.8000\n",
            "Epoch 76/100\n",
            "223/223 [==============================] - 0s 74us/sample - loss: 0.2860 - acc: 0.8744 - val_loss: 0.3326 - val_acc: 0.8000\n",
            "Epoch 77/100\n",
            "223/223 [==============================] - 0s 77us/sample - loss: 0.2844 - acc: 0.8744 - val_loss: 0.3348 - val_acc: 0.8000\n",
            "Epoch 78/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.2832 - acc: 0.8744 - val_loss: 0.3336 - val_acc: 0.8000\n",
            "Epoch 79/100\n",
            "223/223 [==============================] - 0s 92us/sample - loss: 0.2821 - acc: 0.8744 - val_loss: 0.3333 - val_acc: 0.8000\n",
            "Epoch 80/100\n",
            "223/223 [==============================] - 0s 81us/sample - loss: 0.2811 - acc: 0.8744 - val_loss: 0.3320 - val_acc: 0.8000\n",
            "Epoch 81/100\n",
            "223/223 [==============================] - 0s 88us/sample - loss: 0.2805 - acc: 0.8744 - val_loss: 0.3281 - val_acc: 0.8000\n",
            "Epoch 82/100\n",
            "223/223 [==============================] - 0s 76us/sample - loss: 0.2789 - acc: 0.8744 - val_loss: 0.3260 - val_acc: 0.8000\n",
            "Epoch 83/100\n",
            "223/223 [==============================] - 0s 78us/sample - loss: 0.2785 - acc: 0.8744 - val_loss: 0.3248 - val_acc: 0.8000\n",
            "Epoch 84/100\n",
            "223/223 [==============================] - 0s 72us/sample - loss: 0.2771 - acc: 0.8744 - val_loss: 0.3257 - val_acc: 0.8000\n",
            "Epoch 85/100\n",
            "223/223 [==============================] - 0s 90us/sample - loss: 0.2760 - acc: 0.8744 - val_loss: 0.3255 - val_acc: 0.8000\n",
            "Epoch 86/100\n",
            "223/223 [==============================] - 0s 86us/sample - loss: 0.2753 - acc: 0.8789 - val_loss: 0.3266 - val_acc: 0.8000\n",
            "Epoch 87/100\n",
            "223/223 [==============================] - 0s 88us/sample - loss: 0.2743 - acc: 0.8789 - val_loss: 0.3245 - val_acc: 0.8000\n",
            "Epoch 88/100\n",
            "223/223 [==============================] - 0s 94us/sample - loss: 0.2735 - acc: 0.8789 - val_loss: 0.3240 - val_acc: 0.8000\n",
            "Epoch 89/100\n",
            "223/223 [==============================] - 0s 79us/sample - loss: 0.2735 - acc: 0.8789 - val_loss: 0.3161 - val_acc: 0.8000\n",
            "Epoch 90/100\n",
            "223/223 [==============================] - 0s 90us/sample - loss: 0.2725 - acc: 0.8789 - val_loss: 0.3218 - val_acc: 0.8000\n",
            "Epoch 91/100\n",
            "223/223 [==============================] - 0s 92us/sample - loss: 0.2712 - acc: 0.8789 - val_loss: 0.3173 - val_acc: 0.8000\n",
            "Epoch 92/100\n",
            "223/223 [==============================] - 0s 97us/sample - loss: 0.2702 - acc: 0.8789 - val_loss: 0.3184 - val_acc: 0.8000\n",
            "Epoch 93/100\n",
            "223/223 [==============================] - 0s 94us/sample - loss: 0.2695 - acc: 0.8789 - val_loss: 0.3180 - val_acc: 0.8000\n",
            "Epoch 94/100\n",
            "223/223 [==============================] - 0s 95us/sample - loss: 0.2691 - acc: 0.8834 - val_loss: 0.3149 - val_acc: 0.8000\n",
            "Epoch 95/100\n",
            "223/223 [==============================] - 0s 85us/sample - loss: 0.2682 - acc: 0.8879 - val_loss: 0.3144 - val_acc: 0.8000\n",
            "Epoch 96/100\n",
            "223/223 [==============================] - 0s 93us/sample - loss: 0.2675 - acc: 0.8834 - val_loss: 0.3133 - val_acc: 0.8000\n",
            "Epoch 97/100\n",
            "223/223 [==============================] - 0s 97us/sample - loss: 0.2667 - acc: 0.8834 - val_loss: 0.3138 - val_acc: 0.8000\n",
            "Epoch 98/100\n",
            "223/223 [==============================] - 0s 105us/sample - loss: 0.2657 - acc: 0.8834 - val_loss: 0.3154 - val_acc: 0.8000\n",
            "Epoch 99/100\n",
            "223/223 [==============================] - 0s 100us/sample - loss: 0.2653 - acc: 0.8834 - val_loss: 0.3163 - val_acc: 0.8000\n",
            "Epoch 100/100\n",
            "223/223 [==============================] - 0s 83us/sample - loss: 0.2647 - acc: 0.8834 - val_loss: 0.3120 - val_acc: 0.8000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd58850ae80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MSCYW-97Weg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1420bb4b-d9d2-4d7b-e9cb-3aa677febc24"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(x=xtest_std, y=ytest)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 130us/sample - loss: 0.3133 - acc: 0.8387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wd-QMEL7QK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2ff2de7-0c2a-4758-e373-e51d86bc6b13"
      },
      "source": [
        "print('accuracy=',test_accuracy,'loss=',test_loss)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy= 0.83870965 loss= 0.3133491998718631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir-B2H3o7ZDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}