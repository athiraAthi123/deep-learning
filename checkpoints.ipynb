{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "checkpoints.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6OQfczTMTmu",
        "colab_type": "text"
      },
      "source": [
        "LIVER PATIENTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p_CBRKGMV72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGzhBlLPMXpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(\"indian_liver_patient.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nnaqbh4WZ3v",
        "colab_type": "code",
        "outputId": "5ac71701-1c57-4616-fe5a-3766c90ce198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Total_Bilirubin</th>\n",
              "      <th>Direct_Bilirubin</th>\n",
              "      <th>Alkaline_Phosphotase</th>\n",
              "      <th>Alamine_Aminotransferase</th>\n",
              "      <th>Aspartate_Aminotransferase</th>\n",
              "      <th>Total_Protiens</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Albumin_and_Globulin_Ratio</th>\n",
              "      <th>Dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>187</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "      <td>Male</td>\n",
              "      <td>10.9</td>\n",
              "      <td>5.5</td>\n",
              "      <td>699</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62</td>\n",
              "      <td>Male</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>490</td>\n",
              "      <td>60</td>\n",
              "      <td>68</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>182</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>195</td>\n",
              "      <td>27</td>\n",
              "      <td>59</td>\n",
              "      <td>7.3</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>60</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>500</td>\n",
              "      <td>20</td>\n",
              "      <td>34</td>\n",
              "      <td>5.9</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.37</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>579</th>\n",
              "      <td>40</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.1</td>\n",
              "      <td>98</td>\n",
              "      <td>35</td>\n",
              "      <td>31</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580</th>\n",
              "      <td>52</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>245</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>6.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581</th>\n",
              "      <td>31</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>184</td>\n",
              "      <td>29</td>\n",
              "      <td>32</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>38</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.3</td>\n",
              "      <td>216</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>583 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Gender  Total_Bilirubin  ...  Albumin  Albumin_and_Globulin_Ratio  Dataset\n",
              "0     65  Female              0.7  ...      3.3                        0.90        1\n",
              "1     62    Male             10.9  ...      3.2                        0.74        1\n",
              "2     62    Male              7.3  ...      3.3                        0.89        1\n",
              "3     58    Male              1.0  ...      3.4                        1.00        1\n",
              "4     72    Male              3.9  ...      2.4                        0.40        1\n",
              "..   ...     ...              ...  ...      ...                         ...      ...\n",
              "578   60    Male              0.5  ...      1.6                        0.37        2\n",
              "579   40    Male              0.6  ...      3.2                        1.10        1\n",
              "580   52    Male              0.8  ...      3.2                        1.00        1\n",
              "581   31    Male              1.3  ...      3.4                        1.00        1\n",
              "582   38    Male              1.0  ...      4.4                        1.50        2\n",
              "\n",
              "[583 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JYxPGe9Mz4h",
        "colab_type": "code",
        "outputId": "5bda37d8-097d-43d9-8539-714e5d638e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnMZX-tRNEYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfILn7woNMAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrTB_6a1NTHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZWNbIK5NWZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUCxG9XPNY9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc=StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aox4m1U3NrvC",
        "colab_type": "code",
        "outputId": "d4ded407-9c1b-43c7-c34c-f40bb5fd1bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 583 entries, 0 to 582\n",
            "Data columns (total 11 columns):\n",
            "Age                           583 non-null int64\n",
            "Gender                        583 non-null object\n",
            "Total_Bilirubin               583 non-null float64\n",
            "Direct_Bilirubin              583 non-null float64\n",
            "Alkaline_Phosphotase          583 non-null int64\n",
            "Alamine_Aminotransferase      583 non-null int64\n",
            "Aspartate_Aminotransferase    583 non-null int64\n",
            "Total_Protiens                583 non-null float64\n",
            "Albumin                       583 non-null float64\n",
            "Albumin_and_Globulin_Ratio    579 non-null float64\n",
            "Dataset                       583 non-null int64\n",
            "dtypes: float64(5), int64(5), object(1)\n",
            "memory usage: 50.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1etwzaOTNrpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lb=LabelEncoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIbyEn89Nrn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['Gender']=lb.fit_transform(data['Gender'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es6nYS1MNrjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.fillna(data.mean(),inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNxLd64FNrhz",
        "colab_type": "code",
        "outputId": "ddb5b307-fdf8-430a-db0b-e463b110a423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4SCBUIaNrWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=data.drop('Dataset',axis=1)\n",
        "y=data['Dataset']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUABqR8cNrSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.33,stratify=y,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMrdQ8WNNasK",
        "colab_type": "code",
        "outputId": "5b93bbbc-17a7-47d6-b0b7-b311df886201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sc.fit(xtrain)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrWFwPraOXuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain_std=sc.transform(xtrain)\n",
        "xtest_std=sc.transform(xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPPrI2ccObLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_DNN = keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hFOHuwxPHnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_DNN.add(keras.layers.Dense(units=15, activation='relu', input_shape=xtrain.shape[1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgsXnhJJPJsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model_DNN.add(keras.layers.BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld6o_vvvPR3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model_DNN.add(keras.layers.Dropout(0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E58p65WUPT5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_DNN.add(keras.layers.Dense(units=12, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Pgu13iPV58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model_DNN.add(keras.layers.Dropout(0.1))\n",
        "model_DNN.add(keras.layers.Dense(units=8, activation='relu'))\n",
        "model_DNN.add(keras.layers.Dense(units=4, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OENkAU0APami",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_DNN.add(keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q96OQO1BPzBH",
        "colab_type": "code",
        "outputId": "ccdfed53-fc08-4a27-cfca-37541b39dfba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model_DNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZcveZ13P5vF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=100, restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3An6FxwQGxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_model_checkpoint =keras.callbacks.ModelCheckpoint(\"bestModel_liver.h5\",save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhhZzvGXQPgu",
        "colab_type": "code",
        "outputId": "99f17727-6dff-41b3-99fd-4ce52fddf599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_DNN.fit(x=xtrain_std, y=ytrain, validation_split=0.1,epochs=200, batch_size=32, callbacks=[cb_early_stopping,cb_model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 351 samples, validate on 39 samples\n",
            "Epoch 1/200\n",
            "351/351 [==============================] - 1s 2ms/sample - loss: 0.5401 - acc: 0.7094 - val_loss: 0.5892 - val_acc: 0.7436\n",
            "Epoch 2/200\n",
            "351/351 [==============================] - 0s 167us/sample - loss: 0.4204 - acc: 0.7094 - val_loss: 0.5113 - val_acc: 0.7436\n",
            "Epoch 3/200\n",
            "351/351 [==============================] - 0s 176us/sample - loss: 0.2476 - acc: 0.7094 - val_loss: 0.4066 - val_acc: 0.7436\n",
            "Epoch 4/200\n",
            "351/351 [==============================] - 0s 170us/sample - loss: 0.0481 - acc: 0.7094 - val_loss: 0.2570 - val_acc: 0.7436\n",
            "Epoch 5/200\n",
            "351/351 [==============================] - 0s 181us/sample - loss: -0.2051 - acc: 0.7094 - val_loss: 0.0502 - val_acc: 0.7436\n",
            "Epoch 6/200\n",
            "351/351 [==============================] - 0s 184us/sample - loss: -0.5378 - acc: 0.7094 - val_loss: -0.2090 - val_acc: 0.7436\n",
            "Epoch 7/200\n",
            "351/351 [==============================] - 0s 175us/sample - loss: -0.8973 - acc: 0.7094 - val_loss: -0.5264 - val_acc: 0.7436\n",
            "Epoch 8/200\n",
            "351/351 [==============================] - 0s 166us/sample - loss: -1.3733 - acc: 0.7094 - val_loss: -0.9120 - val_acc: 0.7436\n",
            "Epoch 9/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -2.0337 - acc: 0.7094 - val_loss: -1.4473 - val_acc: 0.7436\n",
            "Epoch 10/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -2.9047 - acc: 0.7094 - val_loss: -2.2336 - val_acc: 0.7436\n",
            "Epoch 11/200\n",
            "351/351 [==============================] - 0s 197us/sample - loss: -4.3700 - acc: 0.7094 - val_loss: -3.4754 - val_acc: 0.7436\n",
            "Epoch 12/200\n",
            "351/351 [==============================] - 0s 185us/sample - loss: -6.4396 - acc: 0.7094 - val_loss: -5.3980 - val_acc: 0.7436\n",
            "Epoch 13/200\n",
            "351/351 [==============================] - 0s 176us/sample - loss: -9.7869 - acc: 0.7094 - val_loss: -8.4946 - val_acc: 0.7436\n",
            "Epoch 14/200\n",
            "351/351 [==============================] - 0s 162us/sample - loss: -14.2065 - acc: 0.7094 - val_loss: -13.3213 - val_acc: 0.7436\n",
            "Epoch 15/200\n",
            "351/351 [==============================] - 0s 164us/sample - loss: -21.8503 - acc: 0.7094 - val_loss: -20.3117 - val_acc: 0.7436\n",
            "Epoch 16/200\n",
            "351/351 [==============================] - 0s 173us/sample - loss: -32.2882 - acc: 0.7094 - val_loss: -30.9101 - val_acc: 0.7436\n",
            "Epoch 17/200\n",
            "351/351 [==============================] - 0s 167us/sample - loss: -46.0505 - acc: 0.7094 - val_loss: -46.1922 - val_acc: 0.7436\n",
            "Epoch 18/200\n",
            "351/351 [==============================] - 0s 173us/sample - loss: -66.5521 - acc: 0.7094 - val_loss: -68.6243 - val_acc: 0.7436\n",
            "Epoch 19/200\n",
            "351/351 [==============================] - 0s 182us/sample - loss: -95.6277 - acc: 0.7094 - val_loss: -100.3642 - val_acc: 0.7436\n",
            "Epoch 20/200\n",
            "351/351 [==============================] - 0s 163us/sample - loss: -138.1348 - acc: 0.7094 - val_loss: -145.2660 - val_acc: 0.7436\n",
            "Epoch 21/200\n",
            "351/351 [==============================] - 0s 162us/sample - loss: -197.9002 - acc: 0.7094 - val_loss: -209.0151 - val_acc: 0.7436\n",
            "Epoch 22/200\n",
            "351/351 [==============================] - 0s 172us/sample - loss: -269.8663 - acc: 0.7094 - val_loss: -299.8312 - val_acc: 0.7436\n",
            "Epoch 23/200\n",
            "351/351 [==============================] - 0s 159us/sample - loss: -366.5467 - acc: 0.7094 - val_loss: -425.1996 - val_acc: 0.7436\n",
            "Epoch 24/200\n",
            "351/351 [==============================] - 0s 198us/sample - loss: -512.4658 - acc: 0.7094 - val_loss: -583.8423 - val_acc: 0.7436\n",
            "Epoch 25/200\n",
            "351/351 [==============================] - 0s 173us/sample - loss: -685.5230 - acc: 0.7094 - val_loss: -804.3656 - val_acc: 0.7436\n",
            "Epoch 26/200\n",
            "351/351 [==============================] - 0s 163us/sample - loss: -917.7143 - acc: 0.7094 - val_loss: -1087.7229 - val_acc: 0.7436\n",
            "Epoch 27/200\n",
            "351/351 [==============================] - 0s 163us/sample - loss: -1215.7928 - acc: 0.7094 - val_loss: -1453.2119 - val_acc: 0.7436\n",
            "Epoch 28/200\n",
            "351/351 [==============================] - 0s 161us/sample - loss: -1570.8961 - acc: 0.7094 - val_loss: -1926.5468 - val_acc: 0.7436\n",
            "Epoch 29/200\n",
            "351/351 [==============================] - 0s 184us/sample - loss: -2075.4039 - acc: 0.7094 - val_loss: -2496.5215 - val_acc: 0.7436\n",
            "Epoch 30/200\n",
            "351/351 [==============================] - 0s 180us/sample - loss: -2593.7934 - acc: 0.7094 - val_loss: -3217.1464 - val_acc: 0.7436\n",
            "Epoch 31/200\n",
            "351/351 [==============================] - 0s 173us/sample - loss: -3301.2881 - acc: 0.7094 - val_loss: -4109.9570 - val_acc: 0.7436\n",
            "Epoch 32/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -4225.2148 - acc: 0.7094 - val_loss: -5187.2469 - val_acc: 0.7436\n",
            "Epoch 33/200\n",
            "351/351 [==============================] - 0s 172us/sample - loss: -5388.2576 - acc: 0.7094 - val_loss: -6425.5844 - val_acc: 0.7436\n",
            "Epoch 34/200\n",
            "351/351 [==============================] - 0s 182us/sample - loss: -6566.6957 - acc: 0.7094 - val_loss: -7961.8638 - val_acc: 0.7436\n",
            "Epoch 35/200\n",
            "351/351 [==============================] - 0s 161us/sample - loss: -8336.1618 - acc: 0.7094 - val_loss: -9788.8024 - val_acc: 0.7436\n",
            "Epoch 36/200\n",
            "351/351 [==============================] - 0s 159us/sample - loss: -9968.0797 - acc: 0.7094 - val_loss: -11933.8048 - val_acc: 0.7436\n",
            "Epoch 37/200\n",
            "351/351 [==============================] - 0s 172us/sample - loss: -12001.3477 - acc: 0.7094 - val_loss: -14471.5206 - val_acc: 0.7436\n",
            "Epoch 38/200\n",
            "351/351 [==============================] - 0s 157us/sample - loss: -14795.7075 - acc: 0.7094 - val_loss: -17265.0909 - val_acc: 0.7436\n",
            "Epoch 39/200\n",
            "351/351 [==============================] - 0s 158us/sample - loss: -17656.5334 - acc: 0.7094 - val_loss: -20515.0769 - val_acc: 0.7436\n",
            "Epoch 40/200\n",
            "351/351 [==============================] - 0s 164us/sample - loss: -21460.3430 - acc: 0.7094 - val_loss: -24320.8305 - val_acc: 0.7436\n",
            "Epoch 41/200\n",
            "351/351 [==============================] - 0s 178us/sample - loss: -25313.2387 - acc: 0.7094 - val_loss: -28862.5386 - val_acc: 0.7436\n",
            "Epoch 42/200\n",
            "351/351 [==============================] - 0s 180us/sample - loss: -29972.4780 - acc: 0.7094 - val_loss: -33927.4420 - val_acc: 0.7436\n",
            "Epoch 43/200\n",
            "351/351 [==============================] - 0s 192us/sample - loss: -35637.7771 - acc: 0.7094 - val_loss: -39951.2240 - val_acc: 0.7436\n",
            "Epoch 44/200\n",
            "351/351 [==============================] - 0s 162us/sample - loss: -41202.8985 - acc: 0.7094 - val_loss: -46550.1937 - val_acc: 0.7436\n",
            "Epoch 45/200\n",
            "351/351 [==============================] - 0s 171us/sample - loss: -48373.0468 - acc: 0.7094 - val_loss: -53661.8059 - val_acc: 0.7436\n",
            "Epoch 46/200\n",
            "351/351 [==============================] - 0s 175us/sample - loss: -56845.1481 - acc: 0.7094 - val_loss: -62412.7564 - val_acc: 0.7436\n",
            "Epoch 47/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -65075.8594 - acc: 0.7094 - val_loss: -72172.8232 - val_acc: 0.7436\n",
            "Epoch 48/200\n",
            "351/351 [==============================] - 0s 167us/sample - loss: -77205.4441 - acc: 0.7094 - val_loss: -82502.1050 - val_acc: 0.7436\n",
            "Epoch 49/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -88495.5537 - acc: 0.7094 - val_loss: -94054.0100 - val_acc: 0.7436\n",
            "Epoch 50/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -102146.3435 - acc: 0.7094 - val_loss: -106921.2115 - val_acc: 0.7436\n",
            "Epoch 51/200\n",
            "351/351 [==============================] - 0s 164us/sample - loss: -115711.7132 - acc: 0.7094 - val_loss: -121697.4653 - val_acc: 0.7436\n",
            "Epoch 52/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -130862.3845 - acc: 0.7094 - val_loss: -138248.1879 - val_acc: 0.7436\n",
            "Epoch 53/200\n",
            "351/351 [==============================] - 0s 162us/sample - loss: -148358.5031 - acc: 0.7094 - val_loss: -155352.6835 - val_acc: 0.7436\n",
            "Epoch 54/200\n",
            "351/351 [==============================] - 0s 153us/sample - loss: -166946.0842 - acc: 0.7094 - val_loss: -175447.6690 - val_acc: 0.7436\n",
            "Epoch 55/200\n",
            "351/351 [==============================] - 0s 171us/sample - loss: -189677.7243 - acc: 0.7094 - val_loss: -197030.2312 - val_acc: 0.7436\n",
            "Epoch 56/200\n",
            "351/351 [==============================] - 0s 156us/sample - loss: -213373.3722 - acc: 0.7094 - val_loss: -219826.9239 - val_acc: 0.7436\n",
            "Epoch 57/200\n",
            "351/351 [==============================] - 0s 152us/sample - loss: -236729.8963 - acc: 0.7094 - val_loss: -245069.1242 - val_acc: 0.7436\n",
            "Epoch 58/200\n",
            "351/351 [==============================] - 0s 167us/sample - loss: -266294.7539 - acc: 0.7094 - val_loss: -273288.5128 - val_acc: 0.7436\n",
            "Epoch 59/200\n",
            "351/351 [==============================] - 0s 154us/sample - loss: -296222.2546 - acc: 0.7094 - val_loss: -303860.8317 - val_acc: 0.7436\n",
            "Epoch 60/200\n",
            "351/351 [==============================] - 0s 160us/sample - loss: -331740.5546 - acc: 0.7094 - val_loss: -337717.9744 - val_acc: 0.7436\n",
            "Epoch 61/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -371276.8568 - acc: 0.7094 - val_loss: -375089.0465 - val_acc: 0.7436\n",
            "Epoch 62/200\n",
            "351/351 [==============================] - 0s 160us/sample - loss: -411148.1978 - acc: 0.7094 - val_loss: -413925.8694 - val_acc: 0.7436\n",
            "Epoch 63/200\n",
            "351/351 [==============================] - 0s 167us/sample - loss: -452699.4722 - acc: 0.7094 - val_loss: -461294.4960 - val_acc: 0.7436\n",
            "Epoch 64/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -508204.9374 - acc: 0.7094 - val_loss: -506404.7692 - val_acc: 0.7436\n",
            "Epoch 65/200\n",
            "351/351 [==============================] - 0s 171us/sample - loss: -551873.3134 - acc: 0.7094 - val_loss: -557347.5769 - val_acc: 0.7436\n",
            "Epoch 66/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -604075.1435 - acc: 0.7094 - val_loss: -615197.9247 - val_acc: 0.7436\n",
            "Epoch 67/200\n",
            "351/351 [==============================] - 0s 174us/sample - loss: -673053.0260 - acc: 0.7094 - val_loss: -676550.1394 - val_acc: 0.7436\n",
            "Epoch 68/200\n",
            "351/351 [==============================] - 0s 171us/sample - loss: -742143.9469 - acc: 0.7094 - val_loss: -737742.4079 - val_acc: 0.7436\n",
            "Epoch 69/200\n",
            "351/351 [==============================] - 0s 185us/sample - loss: -811790.1790 - acc: 0.7094 - val_loss: -804227.8221 - val_acc: 0.7436\n",
            "Epoch 70/200\n",
            "351/351 [==============================] - 0s 159us/sample - loss: -879602.5176 - acc: 0.7094 - val_loss: -885131.9038 - val_acc: 0.7436\n",
            "Epoch 71/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -957781.7582 - acc: 0.7094 - val_loss: -965013.6554 - val_acc: 0.7436\n",
            "Epoch 72/200\n",
            "351/351 [==============================] - 0s 160us/sample - loss: -1042726.4776 - acc: 0.7094 - val_loss: -1049227.9423 - val_acc: 0.7436\n",
            "Epoch 73/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -1141448.2902 - acc: 0.7094 - val_loss: -1138421.5481 - val_acc: 0.7436\n",
            "Epoch 74/200\n",
            "351/351 [==============================] - 0s 169us/sample - loss: -1239661.6873 - acc: 0.7094 - val_loss: -1240298.3654 - val_acc: 0.7436\n",
            "Epoch 75/200\n",
            "351/351 [==============================] - 0s 159us/sample - loss: -1367101.0702 - acc: 0.7094 - val_loss: -1344998.3253 - val_acc: 0.7436\n",
            "Epoch 76/200\n",
            "351/351 [==============================] - 0s 167us/sample - loss: -1484941.1895 - acc: 0.7094 - val_loss: -1454110.4199 - val_acc: 0.7436\n",
            "Epoch 77/200\n",
            "351/351 [==============================] - 0s 158us/sample - loss: -1600307.7689 - acc: 0.7094 - val_loss: -1571815.1651 - val_acc: 0.7436\n",
            "Epoch 78/200\n",
            "351/351 [==============================] - 0s 180us/sample - loss: -1741246.9736 - acc: 0.7094 - val_loss: -1703472.9006 - val_acc: 0.7436\n",
            "Epoch 79/200\n",
            "351/351 [==============================] - 0s 170us/sample - loss: -1878276.8255 - acc: 0.7094 - val_loss: -1836892.1090 - val_acc: 0.7436\n",
            "Epoch 80/200\n",
            "351/351 [==============================] - 0s 170us/sample - loss: -1996257.6417 - acc: 0.7094 - val_loss: -1978272.9551 - val_acc: 0.7436\n",
            "Epoch 81/200\n",
            "351/351 [==============================] - 0s 179us/sample - loss: -2182913.4633 - acc: 0.7094 - val_loss: -2129957.2179 - val_acc: 0.7436\n",
            "Epoch 82/200\n",
            "351/351 [==============================] - 0s 171us/sample - loss: -2319820.7984 - acc: 0.7094 - val_loss: -2290518.6442 - val_acc: 0.7436\n",
            "Epoch 83/200\n",
            "351/351 [==============================] - 0s 171us/sample - loss: -2528790.4060 - acc: 0.7094 - val_loss: -2447755.3910 - val_acc: 0.7436\n",
            "Epoch 84/200\n",
            "351/351 [==============================] - 0s 154us/sample - loss: -2679363.3903 - acc: 0.7094 - val_loss: -2632769.3365 - val_acc: 0.7436\n",
            "Epoch 85/200\n",
            "351/351 [==============================] - 0s 195us/sample - loss: -2939665.7311 - acc: 0.7094 - val_loss: -2831389.5064 - val_acc: 0.7436\n",
            "Epoch 86/200\n",
            "351/351 [==============================] - 0s 170us/sample - loss: -3137348.8932 - acc: 0.7094 - val_loss: -3035194.5000 - val_acc: 0.7436\n",
            "Epoch 87/200\n",
            "351/351 [==============================] - 0s 163us/sample - loss: -3388432.5114 - acc: 0.7094 - val_loss: -3261611.2564 - val_acc: 0.7436\n",
            "Epoch 88/200\n",
            "351/351 [==============================] - 0s 179us/sample - loss: -3560063.8013 - acc: 0.7094 - val_loss: -3482234.2115 - val_acc: 0.7436\n",
            "Epoch 89/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -3863358.1724 - acc: 0.7094 - val_loss: -3721255.5256 - val_acc: 0.7436\n",
            "Epoch 90/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -4027390.5912 - acc: 0.7094 - val_loss: -4003172.1026 - val_acc: 0.7436\n",
            "Epoch 91/200\n",
            "351/351 [==============================] - 0s 183us/sample - loss: -4394250.1225 - acc: 0.7094 - val_loss: -4280256.0000 - val_acc: 0.7436\n",
            "Epoch 92/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -4565443.8048 - acc: 0.7094 - val_loss: -4571095.5769 - val_acc: 0.7436\n",
            "Epoch 93/200\n",
            "351/351 [==============================] - 0s 163us/sample - loss: -4997110.1211 - acc: 0.7094 - val_loss: -4858864.4103 - val_acc: 0.7436\n",
            "Epoch 94/200\n",
            "351/351 [==============================] - 0s 169us/sample - loss: -5277840.4900 - acc: 0.7094 - val_loss: -5171824.0000 - val_acc: 0.7436\n",
            "Epoch 95/200\n",
            "351/351 [==============================] - 0s 166us/sample - loss: -5704643.3120 - acc: 0.7094 - val_loss: -5524932.5641 - val_acc: 0.7436\n",
            "Epoch 96/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -6047600.7393 - acc: 0.7094 - val_loss: -5846874.0256 - val_acc: 0.7436\n",
            "Epoch 97/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -6322350.3433 - acc: 0.7094 - val_loss: -6211492.7051 - val_acc: 0.7436\n",
            "Epoch 98/200\n",
            "351/351 [==============================] - 0s 166us/sample - loss: -6847779.0000 - acc: 0.7094 - val_loss: -6587697.6410 - val_acc: 0.7436\n",
            "Epoch 99/200\n",
            "351/351 [==============================] - 0s 174us/sample - loss: -7203731.0299 - acc: 0.7094 - val_loss: -6984223.2179 - val_acc: 0.7436\n",
            "Epoch 100/200\n",
            "351/351 [==============================] - 0s 163us/sample - loss: -7714137.2365 - acc: 0.7094 - val_loss: -7419115.1859 - val_acc: 0.7436\n",
            "Epoch 101/200\n",
            "351/351 [==============================] - 0s 178us/sample - loss: -8069527.4416 - acc: 0.7094 - val_loss: -7828814.4359 - val_acc: 0.7436\n",
            "Epoch 102/200\n",
            "351/351 [==============================] - 0s 159us/sample - loss: -8556026.2550 - acc: 0.7094 - val_loss: -8263704.8718 - val_acc: 0.7436\n",
            "Epoch 103/200\n",
            "351/351 [==============================] - 0s 175us/sample - loss: -9138957.7664 - acc: 0.7094 - val_loss: -8688740.1026 - val_acc: 0.7436\n",
            "Epoch 104/200\n",
            "351/351 [==============================] - 0s 160us/sample - loss: -9644344.3362 - acc: 0.7094 - val_loss: -9181870.9744 - val_acc: 0.7436\n",
            "Epoch 105/200\n",
            "351/351 [==============================] - 0s 158us/sample - loss: -10183172.5499 - acc: 0.7094 - val_loss: -9746880.9744 - val_acc: 0.7436\n",
            "Epoch 106/200\n",
            "351/351 [==============================] - 0s 163us/sample - loss: -10671311.3789 - acc: 0.7094 - val_loss: -10272896.1538 - val_acc: 0.7436\n",
            "Epoch 107/200\n",
            "351/351 [==============================] - 0s 167us/sample - loss: -11392067.6325 - acc: 0.7094 - val_loss: -10891326.0000 - val_acc: 0.7436\n",
            "Epoch 108/200\n",
            "351/351 [==============================] - 0s 170us/sample - loss: -12067065.2806 - acc: 0.7094 - val_loss: -11560120.9487 - val_acc: 0.7436\n",
            "Epoch 109/200\n",
            "351/351 [==============================] - 0s 157us/sample - loss: -12826743.3533 - acc: 0.7094 - val_loss: -12208851.4359 - val_acc: 0.7436\n",
            "Epoch 110/200\n",
            "351/351 [==============================] - 0s 170us/sample - loss: -13692073.1738 - acc: 0.7094 - val_loss: -12789552.3077 - val_acc: 0.7436\n",
            "Epoch 111/200\n",
            "351/351 [==============================] - 0s 161us/sample - loss: -14207458.9672 - acc: 0.7094 - val_loss: -13491711.8077 - val_acc: 0.7436\n",
            "Epoch 112/200\n",
            "351/351 [==============================] - 0s 158us/sample - loss: -14689626.9687 - acc: 0.7094 - val_loss: -14206266.5641 - val_acc: 0.7436\n",
            "Epoch 113/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -15829127.5043 - acc: 0.7094 - val_loss: -14776342.7949 - val_acc: 0.7436\n",
            "Epoch 114/200\n",
            "351/351 [==============================] - 0s 166us/sample - loss: -16303355.5527 - acc: 0.7094 - val_loss: -15526192.9231 - val_acc: 0.7436\n",
            "Epoch 115/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -17462417.7379 - acc: 0.7094 - val_loss: -16315860.6154 - val_acc: 0.7436\n",
            "Epoch 116/200\n",
            "351/351 [==============================] - 0s 179us/sample - loss: -18130044.5527 - acc: 0.7094 - val_loss: -17136671.8462 - val_acc: 0.7436\n",
            "Epoch 117/200\n",
            "351/351 [==============================] - 0s 178us/sample - loss: -19138161.1282 - acc: 0.7094 - val_loss: -17965385.8462 - val_acc: 0.7436\n",
            "Epoch 118/200\n",
            "351/351 [==============================] - 0s 166us/sample - loss: -20215791.4131 - acc: 0.7094 - val_loss: -18872559.2308 - val_acc: 0.7436\n",
            "Epoch 119/200\n",
            "351/351 [==============================] - 0s 213us/sample - loss: -21053910.1140 - acc: 0.7094 - val_loss: -19804280.7692 - val_acc: 0.7436\n",
            "Epoch 120/200\n",
            "351/351 [==============================] - 0s 163us/sample - loss: -21940551.0826 - acc: 0.7094 - val_loss: -20687529.0256 - val_acc: 0.7436\n",
            "Epoch 121/200\n",
            "351/351 [==============================] - 0s 159us/sample - loss: -22878192.2877 - acc: 0.7094 - val_loss: -21793258.7692 - val_acc: 0.7436\n",
            "Epoch 122/200\n",
            "351/351 [==============================] - 0s 189us/sample - loss: -23510317.1966 - acc: 0.7094 - val_loss: -22842699.0256 - val_acc: 0.7436\n",
            "Epoch 123/200\n",
            "351/351 [==============================] - 0s 171us/sample - loss: -25252486.5071 - acc: 0.7094 - val_loss: -23926985.3846 - val_acc: 0.7436\n",
            "Epoch 124/200\n",
            "351/351 [==============================] - 0s 171us/sample - loss: -26203843.3561 - acc: 0.7094 - val_loss: -24933012.1538 - val_acc: 0.7436\n",
            "Epoch 125/200\n",
            "351/351 [==============================] - 0s 187us/sample - loss: -28259330.2393 - acc: 0.7094 - val_loss: -26046731.6923 - val_acc: 0.7436\n",
            "Epoch 126/200\n",
            "351/351 [==============================] - 0s 189us/sample - loss: -29395416.7635 - acc: 0.7094 - val_loss: -27176247.5385 - val_acc: 0.7436\n",
            "Epoch 127/200\n",
            "351/351 [==============================] - 0s 159us/sample - loss: -30113819.7493 - acc: 0.7094 - val_loss: -28450292.4103 - val_acc: 0.7436\n",
            "Epoch 128/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -31335833.3219 - acc: 0.7094 - val_loss: -29776836.7179 - val_acc: 0.7436\n",
            "Epoch 129/200\n",
            "351/351 [==============================] - 0s 172us/sample - loss: -32827450.6325 - acc: 0.7094 - val_loss: -31106875.0769 - val_acc: 0.7436\n",
            "Epoch 130/200\n",
            "351/351 [==============================] - 0s 190us/sample - loss: -34492096.7293 - acc: 0.7094 - val_loss: -32638616.3590 - val_acc: 0.7436\n",
            "Epoch 131/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -36034072.4672 - acc: 0.7094 - val_loss: -33945059.2821 - val_acc: 0.7436\n",
            "Epoch 132/200\n",
            "351/351 [==============================] - 0s 178us/sample - loss: -37627558.8490 - acc: 0.7094 - val_loss: -35289465.8462 - val_acc: 0.7436\n",
            "Epoch 133/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -39420730.7123 - acc: 0.7094 - val_loss: -36776825.4359 - val_acc: 0.7436\n",
            "Epoch 134/200\n",
            "351/351 [==============================] - 0s 174us/sample - loss: -40679636.6610 - acc: 0.7094 - val_loss: -38294393.7436 - val_acc: 0.7436\n",
            "Epoch 135/200\n",
            "351/351 [==============================] - 0s 171us/sample - loss: -42051751.1168 - acc: 0.7094 - val_loss: -39939597.1282 - val_acc: 0.7436\n",
            "Epoch 136/200\n",
            "351/351 [==============================] - 0s 176us/sample - loss: -43746361.5385 - acc: 0.7094 - val_loss: -41675513.4359 - val_acc: 0.7436\n",
            "Epoch 137/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -45759546.8490 - acc: 0.7094 - val_loss: -43359782.4615 - val_acc: 0.7436\n",
            "Epoch 138/200\n",
            "351/351 [==============================] - 0s 172us/sample - loss: -47832275.1681 - acc: 0.7094 - val_loss: -44812924.4103 - val_acc: 0.7436\n",
            "Epoch 139/200\n",
            "351/351 [==============================] - 0s 166us/sample - loss: -49776593.5726 - acc: 0.7094 - val_loss: -46796109.9487 - val_acc: 0.7436\n",
            "Epoch 140/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -51947484.4729 - acc: 0.7094 - val_loss: -48708241.0256 - val_acc: 0.7436\n",
            "Epoch 141/200\n",
            "351/351 [==============================] - 0s 166us/sample - loss: -53337402.2792 - acc: 0.7094 - val_loss: -50821231.1795 - val_acc: 0.7436\n",
            "Epoch 142/200\n",
            "351/351 [==============================] - 0s 181us/sample - loss: -56684883.7607 - acc: 0.7094 - val_loss: -52903680.2051 - val_acc: 0.7436\n",
            "Epoch 143/200\n",
            "351/351 [==============================] - 0s 172us/sample - loss: -58106224.2963 - acc: 0.7094 - val_loss: -54836162.3077 - val_acc: 0.7436\n",
            "Epoch 144/200\n",
            "351/351 [==============================] - 0s 163us/sample - loss: -60801667.0769 - acc: 0.7094 - val_loss: -57169841.8462 - val_acc: 0.7436\n",
            "Epoch 145/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -62557080.3020 - acc: 0.7094 - val_loss: -59073485.2821 - val_acc: 0.7436\n",
            "Epoch 146/200\n",
            "351/351 [==============================] - 0s 159us/sample - loss: -65304946.5869 - acc: 0.7094 - val_loss: -61038695.0256 - val_acc: 0.7436\n",
            "Epoch 147/200\n",
            "351/351 [==============================] - 0s 170us/sample - loss: -66593394.5413 - acc: 0.7094 - val_loss: -63343601.8462 - val_acc: 0.7436\n",
            "Epoch 148/200\n",
            "351/351 [==============================] - 0s 170us/sample - loss: -68658459.3960 - acc: 0.7094 - val_loss: -65574758.0513 - val_acc: 0.7436\n",
            "Epoch 149/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -72752889.7322 - acc: 0.7094 - val_loss: -68254903.3846 - val_acc: 0.7436\n",
            "Epoch 150/200\n",
            "351/351 [==============================] - 0s 173us/sample - loss: -75791209.0940 - acc: 0.7094 - val_loss: -71238204.3077 - val_acc: 0.7436\n",
            "Epoch 151/200\n",
            "351/351 [==============================] - 0s 176us/sample - loss: -78904817.0712 - acc: 0.7094 - val_loss: -73698880.8205 - val_acc: 0.7436\n",
            "Epoch 152/200\n",
            "351/351 [==============================] - 0s 172us/sample - loss: -81340892.9915 - acc: 0.7094 - val_loss: -76547880.0000 - val_acc: 0.7436\n",
            "Epoch 153/200\n",
            "351/351 [==============================] - 0s 172us/sample - loss: -84004295.2934 - acc: 0.7094 - val_loss: -78412347.6923 - val_acc: 0.7436\n",
            "Epoch 154/200\n",
            "351/351 [==============================] - 0s 196us/sample - loss: -85959354.2792 - acc: 0.7094 - val_loss: -81279706.8718 - val_acc: 0.7436\n",
            "Epoch 155/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -90482652.3077 - acc: 0.7094 - val_loss: -84357881.4359 - val_acc: 0.7436\n",
            "Epoch 156/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -93414241.8234 - acc: 0.7094 - val_loss: -87197148.0000 - val_acc: 0.7436\n",
            "Epoch 157/200\n",
            "351/351 [==============================] - 0s 161us/sample - loss: -95224912.1823 - acc: 0.7094 - val_loss: -90608085.5385 - val_acc: 0.7436\n",
            "Epoch 158/200\n",
            "351/351 [==============================] - 0s 162us/sample - loss: -99850073.4587 - acc: 0.7094 - val_loss: -94106230.1538 - val_acc: 0.7436\n",
            "Epoch 159/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -103079662.8148 - acc: 0.7094 - val_loss: -97548339.0256 - val_acc: 0.7436\n",
            "Epoch 160/200\n",
            "351/351 [==============================] - 0s 199us/sample - loss: -105250169.1054 - acc: 0.7094 - val_loss: -101572285.3333 - val_acc: 0.7436\n",
            "Epoch 161/200\n",
            "351/351 [==============================] - 0s 164us/sample - loss: -109776215.0427 - acc: 0.7094 - val_loss: -105112277.7436 - val_acc: 0.7436\n",
            "Epoch 162/200\n",
            "351/351 [==============================] - 0s 161us/sample - loss: -115447289.1168 - acc: 0.7094 - val_loss: -109153672.6154 - val_acc: 0.7436\n",
            "Epoch 163/200\n",
            "351/351 [==============================] - 0s 194us/sample - loss: -117303535.9544 - acc: 0.7094 - val_loss: -112689583.7949 - val_acc: 0.7436\n",
            "Epoch 164/200\n",
            "351/351 [==============================] - 0s 186us/sample - loss: -123390736.3419 - acc: 0.7094 - val_loss: -115766354.2564 - val_acc: 0.7436\n",
            "Epoch 165/200\n",
            "351/351 [==============================] - 0s 185us/sample - loss: -126561745.3903 - acc: 0.7094 - val_loss: -119111631.1795 - val_acc: 0.7436\n",
            "Epoch 166/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -128902123.4416 - acc: 0.7094 - val_loss: -122090849.2308 - val_acc: 0.7436\n",
            "Epoch 167/200\n",
            "351/351 [==============================] - 0s 157us/sample - loss: -136163253.0142 - acc: 0.7094 - val_loss: -125924627.6923 - val_acc: 0.7436\n",
            "Epoch 168/200\n",
            "351/351 [==============================] - 0s 170us/sample - loss: -137254679.6125 - acc: 0.7094 - val_loss: -130197700.9231 - val_acc: 0.7436\n",
            "Epoch 169/200\n",
            "351/351 [==============================] - 0s 164us/sample - loss: -142686417.5954 - acc: 0.7094 - val_loss: -135244668.3077 - val_acc: 0.7436\n",
            "Epoch 170/200\n",
            "351/351 [==============================] - 0s 164us/sample - loss: -149545475.8746 - acc: 0.7094 - val_loss: -139279295.5897 - val_acc: 0.7436\n",
            "Epoch 171/200\n",
            "351/351 [==============================] - 0s 162us/sample - loss: -152095009.9601 - acc: 0.7094 - val_loss: -143913288.8205 - val_acc: 0.7436\n",
            "Epoch 172/200\n",
            "351/351 [==============================] - 0s 176us/sample - loss: -156425675.3960 - acc: 0.7094 - val_loss: -149068445.5385 - val_acc: 0.7436\n",
            "Epoch 173/200\n",
            "351/351 [==============================] - 0s 164us/sample - loss: -161150882.3704 - acc: 0.7094 - val_loss: -153858379.2821 - val_acc: 0.7436\n",
            "Epoch 174/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -168104506.0285 - acc: 0.7094 - val_loss: -158310619.8974 - val_acc: 0.7436\n",
            "Epoch 175/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -173409826.3704 - acc: 0.7094 - val_loss: -162368939.8974 - val_acc: 0.7436\n",
            "Epoch 176/200\n",
            "351/351 [==============================] - 0s 156us/sample - loss: -179244788.9687 - acc: 0.7094 - val_loss: -166948023.7949 - val_acc: 0.7436\n",
            "Epoch 177/200\n",
            "351/351 [==============================] - 0s 161us/sample - loss: -181922519.3846 - acc: 0.7094 - val_loss: -171666156.3077 - val_acc: 0.7436\n",
            "Epoch 178/200\n",
            "351/351 [==============================] - 0s 169us/sample - loss: -187452664.8433 - acc: 0.7094 - val_loss: -176622893.5385 - val_acc: 0.7436\n",
            "Epoch 179/200\n",
            "351/351 [==============================] - 0s 189us/sample - loss: -191228125.1738 - acc: 0.7094 - val_loss: -180316579.6923 - val_acc: 0.7436\n",
            "Epoch 180/200\n",
            "351/351 [==============================] - 0s 174us/sample - loss: -199723396.4672 - acc: 0.7094 - val_loss: -186947602.4615 - val_acc: 0.7436\n",
            "Epoch 181/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -205664478.1766 - acc: 0.7094 - val_loss: -192939336.2051 - val_acc: 0.7436\n",
            "Epoch 182/200\n",
            "351/351 [==============================] - 0s 182us/sample - loss: -214781400.2507 - acc: 0.7094 - val_loss: -197620237.1282 - val_acc: 0.7436\n",
            "Epoch 183/200\n",
            "351/351 [==============================] - 0s 175us/sample - loss: -217316377.3903 - acc: 0.7094 - val_loss: -203231481.8462 - val_acc: 0.7436\n",
            "Epoch 184/200\n",
            "351/351 [==============================] - 0s 166us/sample - loss: -223118657.8234 - acc: 0.7094 - val_loss: -208595908.5128 - val_acc: 0.7436\n",
            "Epoch 185/200\n",
            "351/351 [==============================] - 0s 177us/sample - loss: -225196967.3390 - acc: 0.7094 - val_loss: -214825668.9231 - val_acc: 0.7436\n",
            "Epoch 186/200\n",
            "351/351 [==============================] - 0s 181us/sample - loss: -236348430.7692 - acc: 0.7094 - val_loss: -219409552.4103 - val_acc: 0.7436\n",
            "Epoch 187/200\n",
            "351/351 [==============================] - 0s 175us/sample - loss: -242297838.1311 - acc: 0.7094 - val_loss: -226203825.2308 - val_acc: 0.7436\n",
            "Epoch 188/200\n",
            "351/351 [==============================] - 0s 171us/sample - loss: -251288155.7151 - acc: 0.7094 - val_loss: -233282443.4872 - val_acc: 0.7436\n",
            "Epoch 189/200\n",
            "351/351 [==============================] - 0s 195us/sample - loss: -256809608.0228 - acc: 0.7094 - val_loss: -241645079.7949 - val_acc: 0.7436\n",
            "Epoch 190/200\n",
            "351/351 [==============================] - 0s 184us/sample - loss: -270369974.1538 - acc: 0.7094 - val_loss: -250173386.6667 - val_acc: 0.7436\n",
            "Epoch 191/200\n",
            "351/351 [==============================] - 0s 173us/sample - loss: -275026856.7521 - acc: 0.7094 - val_loss: -254826378.6667 - val_acc: 0.7436\n",
            "Epoch 192/200\n",
            "351/351 [==============================] - 0s 169us/sample - loss: -281737798.3818 - acc: 0.7094 - val_loss: -261970601.8462 - val_acc: 0.7436\n",
            "Epoch 193/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -293557210.5299 - acc: 0.7094 - val_loss: -268510055.3846 - val_acc: 0.7436\n",
            "Epoch 194/200\n",
            "351/351 [==============================] - 0s 165us/sample - loss: -294242195.5100 - acc: 0.7094 - val_loss: -279494261.3333 - val_acc: 0.7436\n",
            "Epoch 195/200\n",
            "351/351 [==============================] - 0s 167us/sample - loss: -302074679.6125 - acc: 0.7094 - val_loss: -287838595.2821 - val_acc: 0.7436\n",
            "Epoch 196/200\n",
            "351/351 [==============================] - 0s 156us/sample - loss: -309431073.5043 - acc: 0.7094 - val_loss: -295239437.9487 - val_acc: 0.7436\n",
            "Epoch 197/200\n",
            "351/351 [==============================] - 0s 167us/sample - loss: -321100548.6496 - acc: 0.7094 - val_loss: -302442454.9744 - val_acc: 0.7436\n",
            "Epoch 198/200\n",
            "351/351 [==============================] - 0s 163us/sample - loss: -328491251.0541 - acc: 0.7094 - val_loss: -311493274.6667 - val_acc: 0.7436\n",
            "Epoch 199/200\n",
            "351/351 [==============================] - 0s 166us/sample - loss: -338469101.1282 - acc: 0.7094 - val_loss: -318343945.6410 - val_acc: 0.7436\n",
            "Epoch 200/200\n",
            "351/351 [==============================] - 0s 168us/sample - loss: -346100234.1197 - acc: 0.7094 - val_loss: -323545799.3846 - val_acc: 0.7436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efeb6006ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjkyOIDwQZr8",
        "colab_type": "code",
        "outputId": "81fc69ca-9b05-43ab-de03-0a7676dc4cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "best_model = keras.models.load_model(\"bestModel_liver.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdDw7lgbQfpL",
        "colab_type": "code",
        "outputId": "caa20b42-0e4a-455e-9579-d6c5bd577d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_accuracy = best_model.evaluate(x=xtest_std, y=ytest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "193/193 [==============================] - 0s 284us/sample - loss: -321301196.2694 - acc: 0.7150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT-_uRyLQg_e",
        "colab_type": "code",
        "outputId": "66904ed1-7977-4881-ca43-75b10937b869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_loss, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-321301196.26943004 0.7150259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FgC7551RXEC",
        "colab_type": "text"
      },
      "source": [
        "fall detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGcbO6HIQlVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(\"falldeteciton.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgmdApfDR0Ac",
        "colab_type": "code",
        "outputId": "66391ab4-1164-4340-d4b4-9bda9a14b824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16382 entries, 0 to 16381\n",
            "Data columns (total 7 columns):\n",
            "ACTIVITY       16382 non-null int64\n",
            "TIME           16382 non-null float64\n",
            "SL             16382 non-null float64\n",
            "EEG            16382 non-null float64\n",
            "BP             16382 non-null int64\n",
            "HR             16382 non-null int64\n",
            "CIRCLUATION    16382 non-null int64\n",
            "dtypes: float64(3), int64(4)\n",
            "memory usage: 896.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlSdVlUCV2KB",
        "colab_type": "code",
        "outputId": "5f9e5e71-1115-43cc-d0ca-34642b46a20e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ACTIVITY', 'TIME', 'SL', 'EEG', 'BP', 'HR', 'CIRCLUATION'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOv57bH4XB8F",
        "colab_type": "code",
        "outputId": "8319f8d6-aa47-407b-cb3f-8ba90701084b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ACTIVITY</th>\n",
              "      <th>TIME</th>\n",
              "      <th>SL</th>\n",
              "      <th>EEG</th>\n",
              "      <th>BP</th>\n",
              "      <th>HR</th>\n",
              "      <th>CIRCLUATION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>4722.92</td>\n",
              "      <td>4019.64</td>\n",
              "      <td>-1600.00</td>\n",
              "      <td>13</td>\n",
              "      <td>79</td>\n",
              "      <td>317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4059.12</td>\n",
              "      <td>2191.03</td>\n",
              "      <td>-1146.08</td>\n",
              "      <td>20</td>\n",
              "      <td>54</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4773.56</td>\n",
              "      <td>2787.99</td>\n",
              "      <td>-1263.38</td>\n",
              "      <td>46</td>\n",
              "      <td>67</td>\n",
              "      <td>224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>8271.27</td>\n",
              "      <td>9545.98</td>\n",
              "      <td>-2848.93</td>\n",
              "      <td>26</td>\n",
              "      <td>138</td>\n",
              "      <td>554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7102.16</td>\n",
              "      <td>14148.80</td>\n",
              "      <td>-2381.15</td>\n",
              "      <td>85</td>\n",
              "      <td>120</td>\n",
              "      <td>809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16377</th>\n",
              "      <td>4</td>\n",
              "      <td>9280.68</td>\n",
              "      <td>11417.00</td>\n",
              "      <td>-3021.64</td>\n",
              "      <td>36</td>\n",
              "      <td>156</td>\n",
              "      <td>654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16378</th>\n",
              "      <td>3</td>\n",
              "      <td>8479.69</td>\n",
              "      <td>9455.54</td>\n",
              "      <td>-2932.85</td>\n",
              "      <td>17</td>\n",
              "      <td>138</td>\n",
              "      <td>554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16379</th>\n",
              "      <td>2</td>\n",
              "      <td>8872.53</td>\n",
              "      <td>27449.90</td>\n",
              "      <td>-2870.00</td>\n",
              "      <td>33</td>\n",
              "      <td>156</td>\n",
              "      <td>1364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16380</th>\n",
              "      <td>4</td>\n",
              "      <td>7738.99</td>\n",
              "      <td>26466.40</td>\n",
              "      <td>-2920.24</td>\n",
              "      <td>97</td>\n",
              "      <td>156</td>\n",
              "      <td>1521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16381</th>\n",
              "      <td>3</td>\n",
              "      <td>9368.34</td>\n",
              "      <td>39149.10</td>\n",
              "      <td>-2970.00</td>\n",
              "      <td>21</td>\n",
              "      <td>196</td>\n",
              "      <td>1885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16382 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ACTIVITY     TIME        SL      EEG  BP   HR  CIRCLUATION\n",
              "0             3  4722.92   4019.64 -1600.00  13   79          317\n",
              "1             2  4059.12   2191.03 -1146.08  20   54          165\n",
              "2             2  4773.56   2787.99 -1263.38  46   67          224\n",
              "3             4  8271.27   9545.98 -2848.93  26  138          554\n",
              "4             4  7102.16  14148.80 -2381.15  85  120          809\n",
              "...         ...      ...       ...      ...  ..  ...          ...\n",
              "16377         4  9280.68  11417.00 -3021.64  36  156          654\n",
              "16378         3  8479.69   9455.54 -2932.85  17  138          554\n",
              "16379         2  8872.53  27449.90 -2870.00  33  156         1364\n",
              "16380         4  7738.99  26466.40 -2920.24  97  156         1521\n",
              "16381         3  9368.34  39149.10 -2970.00  21  196         1885\n",
              "\n",
              "[16382 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPD1GEknWIux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data.drop(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TrIuHXOR41Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=data.drop('ACTIVITY',axis=1)\n",
        "y=data['ACTIVITY']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y574sSTW-tz",
        "colab_type": "code",
        "outputId": "27022c7f-b7c3-4c94-d5be-7b06a265653a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd8S9ImvU524",
        "colab_type": "code",
        "outputId": "50bdbbee-4f69-4c13-f6a1-7a675c53a537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(y)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        3\n",
            "1        2\n",
            "2        2\n",
            "3        4\n",
            "4        4\n",
            "        ..\n",
            "16377    4\n",
            "16378    3\n",
            "16379    2\n",
            "16380    4\n",
            "16381    3\n",
            "Name: ACTIVITY, Length: 16382, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUtKpWuVie92",
        "colab_type": "code",
        "outputId": "127ffb58-cda5-4e0c-ba90-f0af87deffd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(y)\n",
        "np.shape(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16382,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAaf-ee1R6a0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,stratify=y,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tHCFhdiSAO0",
        "colab_type": "code",
        "outputId": "fe8d4d6e-2d34-4924-8d9b-dc074f4172cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sc.fit(xtrain)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGS37tU7SBwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain_std=sc.fit_transform(xtrain)\n",
        "xtest_std=sc.fit_transform(xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6TQz2weSFAK",
        "colab_type": "code",
        "outputId": "7140ae4e-07ba-4c0b-e048-00e528425d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(units=50,activation=\"relu\",input_shape=xtrain.shape[1:]))\n",
        "model_DNN.add(keras.layers.BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-52287ffc20a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_DNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_DNN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFSO1-sTSJZy",
        "colab_type": "code",
        "outputId": "a40404d8-127b-4746-a774-8f2823b92fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(set(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyH-U4GFT-AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_DNN.add(keras.layers.Dropout(0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFg8Tx5sUIRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_DNN.add(keras.layers.Dense(units=12, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpllxtnmSVHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(keras.layers.Dense(units=6,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_o7KFJqTlaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GycmUc52Tnz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=10, restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIlq_lePUOmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_model_checkpoint =keras.callbacks.ModelCheckpoint(\"bestModel_fall.h5\",save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vgBuYzvUUbM",
        "colab_type": "code",
        "outputId": "f5a31a68-b06a-4c60-b284-6824a948cff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "model_DNN.fit(x=xtrain_std, y=ytrain, validation_split=0.1,epochs=100, batch_size=16, callbacks=[cb_early_stopping,cb_model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-647ba128aa13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_DNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxtrain_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb_early_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcb_model_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     \u001b[0mis_compile_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2432\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2433\u001b[0m       \u001b[0mis_compile_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_from_inputs\u001b[0;34m(self, all_inputs, target, orig_inputs, orig_target)\u001b[0m\n\u001b[1;32m   2629\u001b[0m             target, self.outputs)\n\u001b[1;32m   2630\u001b[0m       training_utils.validate_input_types(target, orig_target,\n\u001b[0;32m-> 2631\u001b[0;31m                                           allow_dict=False, field_name='target')\n\u001b[0m\u001b[1;32m   2632\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m         \u001b[0mall_inputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mvalidate_input_types\u001b[0;34m(inp, orig_inp, allow_dict, field_name)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     raise ValueError(\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m'Please provide as model inputs either a single array or a list of '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         'arrays. You passed: {}={}'.format(field_name, orig_inp))\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: target=6684     0\n10909    0\n6433     3\n10202    3\n10021    5\n        ..\n10025    3\n15106    3\n6555     4\n14079    2\n16130    3\nName: ACTIVITY, Length: 13105, dtype: int64"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqgG5pw7UY1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = keras.models.load_model(\"bestModel_liver.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfDxtF2eVZLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss, test_accuracy = best_model.evaluate(x=xtest_std, y=ytest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt7WwZWqVdm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(test_loss, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6LxJBP-Vj0U",
        "colab_type": "text"
      },
      "source": [
        "bio chemical-binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lx065Y_Vi33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1=pd.read_csv(\"column_2C_weka.csv\")\n",
        "data2=pd.read_csv(\"column_3C_weka.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH8suriHXLSK",
        "colab_type": "code",
        "outputId": "6b049f2a-221c-4723-ba72-50bbc242546b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data1.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 310 entries, 0 to 309\n",
            "Data columns (total 7 columns):\n",
            "pelvic_incidence            310 non-null float64\n",
            "pelvic_tilt numeric         310 non-null float64\n",
            "lumbar_lordosis_angle       310 non-null float64\n",
            "sacral_slope                310 non-null float64\n",
            "pelvic_radius               310 non-null float64\n",
            "degree_spondylolisthesis    310 non-null float64\n",
            "class                       310 non-null object\n",
            "dtypes: float64(6), object(1)\n",
            "memory usage: 17.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ItYEr7XYns",
        "colab_type": "code",
        "outputId": "94288528-f3a9-445d-cd83-4c1377895b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data2.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 310 entries, 0 to 309\n",
            "Data columns (total 7 columns):\n",
            "pelvic_incidence            310 non-null float64\n",
            "pelvic_tilt                 310 non-null float64\n",
            "lumbar_lordosis_angle       310 non-null float64\n",
            "sacral_slope                310 non-null float64\n",
            "pelvic_radius               310 non-null float64\n",
            "degree_spondylolisthesis    310 non-null float64\n",
            "class                       310 non-null object\n",
            "dtypes: float64(6), object(1)\n",
            "memory usage: 17.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwrjsTIdXa41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1['class']=lb.fit_transform(data1['class'])\n",
        "data2['class']=lb.fit_transform(data2['class'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLAbeHCgXcj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=data1.drop('class',axis=1)\n",
        "y=data1['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7AplpECXfQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNXVH2XLXjgL",
        "colab_type": "code",
        "outputId": "67e43f99-ba15-4ac8-ed67-417038790015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sc.fit(xtrain)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok9hlPkDXxee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain_std=sc.fit_transform(xtrain)\n",
        "xtest_std=sc.fit_transform(xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZfyP-K4XyX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(units=30,activation=\"relu\",input_shape=xtrain.shape[1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAXfvdHuX14Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(keras.layers.BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcyr8KXTYHYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(keras.layers.Dropout(0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGkWBEDiYOCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(keras.layers.Dense(units=15,activation=\"relu\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0KX-vk0YSEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(keras.layers.Dense(units=8,activation=\"relu\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxHUQ2fgYXQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(keras.layers.Dense(units=4,activation=\"relu\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD9LZG5hYZu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(keras.layers.Dense(units=1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb3KBX6aYcTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JTiV1RGYeM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=10, restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8w9c0sJYj8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_model_checkpoint =keras.callbacks.ModelCheckpoint(\"bestModel_bio-binary.h5\",save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wq4fhsAYrA5",
        "colab_type": "code",
        "outputId": "c53c3ee3-09d0-4ea7-dc7c-091be7ba4f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x=xtrain_std, y=ytrain, validation_split=0.1,epochs=100, batch_size=16, callbacks=[cb_early_stopping,cb_model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 223 samples, validate on 25 samples\n",
            "Epoch 1/100\n",
            "223/223 [==============================] - 1s 5ms/sample - loss: 0.6919 - acc: 0.5336 - val_loss: 0.6898 - val_acc: 0.5600\n",
            "Epoch 2/100\n",
            "223/223 [==============================] - 0s 334us/sample - loss: 0.6502 - acc: 0.6637 - val_loss: 0.6748 - val_acc: 0.6400\n",
            "Epoch 3/100\n",
            "223/223 [==============================] - 0s 289us/sample - loss: 0.6261 - acc: 0.6861 - val_loss: 0.6549 - val_acc: 0.6800\n",
            "Epoch 4/100\n",
            "223/223 [==============================] - 0s 296us/sample - loss: 0.5813 - acc: 0.7085 - val_loss: 0.6282 - val_acc: 0.6800\n",
            "Epoch 5/100\n",
            "223/223 [==============================] - 0s 291us/sample - loss: 0.5407 - acc: 0.7534 - val_loss: 0.5929 - val_acc: 0.6800\n",
            "Epoch 6/100\n",
            "223/223 [==============================] - 0s 302us/sample - loss: 0.5123 - acc: 0.7399 - val_loss: 0.5553 - val_acc: 0.7200\n",
            "Epoch 7/100\n",
            "223/223 [==============================] - 0s 308us/sample - loss: 0.4816 - acc: 0.7758 - val_loss: 0.5218 - val_acc: 0.8000\n",
            "Epoch 8/100\n",
            "223/223 [==============================] - 0s 308us/sample - loss: 0.4621 - acc: 0.7982 - val_loss: 0.4936 - val_acc: 0.8800\n",
            "Epoch 9/100\n",
            "223/223 [==============================] - 0s 305us/sample - loss: 0.4661 - acc: 0.7848 - val_loss: 0.4706 - val_acc: 0.8800\n",
            "Epoch 10/100\n",
            "223/223 [==============================] - 0s 337us/sample - loss: 0.4332 - acc: 0.8072 - val_loss: 0.4518 - val_acc: 0.8800\n",
            "Epoch 11/100\n",
            "223/223 [==============================] - 0s 343us/sample - loss: 0.4456 - acc: 0.7937 - val_loss: 0.4324 - val_acc: 0.8800\n",
            "Epoch 12/100\n",
            "223/223 [==============================] - 0s 312us/sample - loss: 0.4026 - acc: 0.8206 - val_loss: 0.4120 - val_acc: 0.9200\n",
            "Epoch 13/100\n",
            "223/223 [==============================] - 0s 302us/sample - loss: 0.3974 - acc: 0.8206 - val_loss: 0.3916 - val_acc: 0.9200\n",
            "Epoch 14/100\n",
            "223/223 [==============================] - 0s 318us/sample - loss: 0.3645 - acc: 0.8475 - val_loss: 0.3729 - val_acc: 0.9600\n",
            "Epoch 15/100\n",
            "223/223 [==============================] - 0s 317us/sample - loss: 0.3785 - acc: 0.8206 - val_loss: 0.3575 - val_acc: 0.9200\n",
            "Epoch 16/100\n",
            "223/223 [==============================] - 0s 347us/sample - loss: 0.3462 - acc: 0.8520 - val_loss: 0.3416 - val_acc: 0.9200\n",
            "Epoch 17/100\n",
            "223/223 [==============================] - 0s 321us/sample - loss: 0.3332 - acc: 0.8565 - val_loss: 0.3277 - val_acc: 0.9200\n",
            "Epoch 18/100\n",
            "223/223 [==============================] - 0s 323us/sample - loss: 0.3389 - acc: 0.8386 - val_loss: 0.3147 - val_acc: 0.9200\n",
            "Epoch 19/100\n",
            "223/223 [==============================] - 0s 326us/sample - loss: 0.3446 - acc: 0.8610 - val_loss: 0.3088 - val_acc: 0.9200\n",
            "Epoch 20/100\n",
            "223/223 [==============================] - 0s 342us/sample - loss: 0.3474 - acc: 0.8520 - val_loss: 0.2946 - val_acc: 0.9200\n",
            "Epoch 21/100\n",
            "223/223 [==============================] - 0s 357us/sample - loss: 0.2816 - acc: 0.8610 - val_loss: 0.2886 - val_acc: 0.9200\n",
            "Epoch 22/100\n",
            "223/223 [==============================] - 0s 326us/sample - loss: 0.3282 - acc: 0.8520 - val_loss: 0.2872 - val_acc: 0.9200\n",
            "Epoch 23/100\n",
            "223/223 [==============================] - 0s 327us/sample - loss: 0.2674 - acc: 0.8834 - val_loss: 0.2815 - val_acc: 0.9200\n",
            "Epoch 24/100\n",
            "223/223 [==============================] - 0s 337us/sample - loss: 0.3304 - acc: 0.8430 - val_loss: 0.2792 - val_acc: 0.9200\n",
            "Epoch 25/100\n",
            "223/223 [==============================] - 0s 335us/sample - loss: 0.3070 - acc: 0.8475 - val_loss: 0.2770 - val_acc: 0.9200\n",
            "Epoch 26/100\n",
            "223/223 [==============================] - 0s 337us/sample - loss: 0.2924 - acc: 0.8610 - val_loss: 0.2688 - val_acc: 0.9200\n",
            "Epoch 27/100\n",
            "223/223 [==============================] - 0s 166us/sample - loss: 0.3173 - acc: 0.8475 - val_loss: 0.2700 - val_acc: 0.9200\n",
            "Epoch 28/100\n",
            "223/223 [==============================] - 0s 173us/sample - loss: 0.3171 - acc: 0.8430 - val_loss: 0.2708 - val_acc: 0.9200\n",
            "Epoch 29/100\n",
            "223/223 [==============================] - 0s 183us/sample - loss: 0.3015 - acc: 0.8430 - val_loss: 0.2720 - val_acc: 0.9200\n",
            "Epoch 30/100\n",
            "223/223 [==============================] - 0s 327us/sample - loss: 0.3024 - acc: 0.8296 - val_loss: 0.2631 - val_acc: 0.9200\n",
            "Epoch 31/100\n",
            "223/223 [==============================] - 0s 325us/sample - loss: 0.2666 - acc: 0.8655 - val_loss: 0.2585 - val_acc: 0.9200\n",
            "Epoch 32/100\n",
            "223/223 [==============================] - 0s 168us/sample - loss: 0.2795 - acc: 0.8565 - val_loss: 0.2607 - val_acc: 0.9200\n",
            "Epoch 33/100\n",
            "223/223 [==============================] - 0s 182us/sample - loss: 0.3164 - acc: 0.8475 - val_loss: 0.2658 - val_acc: 0.9200\n",
            "Epoch 34/100\n",
            "223/223 [==============================] - 0s 173us/sample - loss: 0.2855 - acc: 0.8655 - val_loss: 0.2656 - val_acc: 0.9200\n",
            "Epoch 35/100\n",
            "223/223 [==============================] - 0s 180us/sample - loss: 0.2797 - acc: 0.8700 - val_loss: 0.2709 - val_acc: 0.9200\n",
            "Epoch 36/100\n",
            "223/223 [==============================] - 0s 176us/sample - loss: 0.2811 - acc: 0.8655 - val_loss: 0.2741 - val_acc: 0.9200\n",
            "Epoch 37/100\n",
            "223/223 [==============================] - 0s 173us/sample - loss: 0.2898 - acc: 0.8834 - val_loss: 0.2735 - val_acc: 0.9200\n",
            "Epoch 38/100\n",
            "223/223 [==============================] - 0s 194us/sample - loss: 0.2799 - acc: 0.8610 - val_loss: 0.2713 - val_acc: 0.9200\n",
            "Epoch 39/100\n",
            "223/223 [==============================] - 0s 187us/sample - loss: 0.2840 - acc: 0.8565 - val_loss: 0.2739 - val_acc: 0.9200\n",
            "Epoch 40/100\n",
            "223/223 [==============================] - 0s 193us/sample - loss: 0.2871 - acc: 0.8700 - val_loss: 0.2690 - val_acc: 0.9200\n",
            "Epoch 41/100\n",
            "223/223 [==============================] - 0s 1ms/sample - loss: 0.2679 - acc: 0.8610 - val_loss: 0.2665 - val_acc: 0.9200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0bec291b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X7evjAPYvT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = keras.models.load_model(\"bestModel_bio-binary.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWlzdqBqY_mJ",
        "colab_type": "code",
        "outputId": "47d38fcd-2343-475c-a442-fc5b53270d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_accuracy = best_model.evaluate(x=xtest_std, y=ytest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 2ms/sample - loss: 0.2398 - acc: 0.8871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WWHFnelZFG4",
        "colab_type": "code",
        "outputId": "202bad64-82fd-4ce7-e009-fcfccd47af6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_loss,test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.23980046952924422 0.88709676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XshJ00NZ7pd",
        "colab_type": "text"
      },
      "source": [
        "bio.multi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A94up8ZCZ9kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=data2.drop('class',axis=1)\n",
        "y=data2['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f814ttZ7aBN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYR_9XfwaFzO",
        "colab_type": "code",
        "outputId": "60d49de6-b72d-49df-f79f-4bff962cec29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sc.fit(xtrain)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhfrfLUMaFxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain_std=sc.fit_transform(xtrain)\n",
        "xtest_std=sc.fit_transform(xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybBNAZ4aaMSj",
        "colab_type": "code",
        "outputId": "31b9ff17-8cfc-4197-8b10-907d4e9bf6ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sq3IeJRZKOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2=keras.models.Sequential()\n",
        "model_2.add(keras.layers.Dense(units=30,activation=\"relu\",input_shape=xtrain.shape[1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2AaWrFGZgMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.add(keras.layers.BatchNormalization())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iuECpLBZnMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.add(keras.layers.Dropout(0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZTE8rUfZsC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.add(keras.layers.Dense(units=15,activation=\"relu\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxzIFG6ZZwka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.add(keras.layers.Dense(units=8,activation=\"relu\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfqBJuHWaRX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.add(keras.layers.Dense(units=3,activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlXJ8qwHb9N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pbrE7gKaWWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',patience=100, restore_best_weights=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlVWC1--b7cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_model_checkpoint =keras.callbacks.ModelCheckpoint(\"bestModel_bio-multi.h5\",save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXYbEGfOcKgV",
        "colab_type": "code",
        "outputId": "d1943749-b924-45ff-cb86-cb4d46c73b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_2.fit(x=xtrain_std, y=ytrain, validation_split=0.1,epochs=100, batch_size=16, callbacks=[cb_early_stopping,cb_model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 223 samples, validate on 25 samples\n",
            "Epoch 1/100\n",
            "223/223 [==============================] - 1s 5ms/sample - loss: 0.2701 - acc: 0.8924 - val_loss: 0.3225 - val_acc: 0.8000\n",
            "Epoch 2/100\n",
            "223/223 [==============================] - 0s 190us/sample - loss: 0.2841 - acc: 0.8700 - val_loss: 0.3398 - val_acc: 0.8000\n",
            "Epoch 3/100\n",
            "223/223 [==============================] - 0s 160us/sample - loss: 0.2838 - acc: 0.8744 - val_loss: 0.3403 - val_acc: 0.8000\n",
            "Epoch 4/100\n",
            "223/223 [==============================] - 0s 162us/sample - loss: 0.2898 - acc: 0.8789 - val_loss: 0.3573 - val_acc: 0.8000\n",
            "Epoch 5/100\n",
            "223/223 [==============================] - 0s 155us/sample - loss: 0.3371 - acc: 0.8789 - val_loss: 0.3476 - val_acc: 0.8000\n",
            "Epoch 6/100\n",
            "223/223 [==============================] - 0s 165us/sample - loss: 0.2824 - acc: 0.8789 - val_loss: 0.3524 - val_acc: 0.8000\n",
            "Epoch 7/100\n",
            "223/223 [==============================] - 0s 163us/sample - loss: 0.2708 - acc: 0.8924 - val_loss: 0.3438 - val_acc: 0.8000\n",
            "Epoch 8/100\n",
            "223/223 [==============================] - 0s 168us/sample - loss: 0.2538 - acc: 0.8879 - val_loss: 0.3446 - val_acc: 0.8000\n",
            "Epoch 9/100\n",
            "223/223 [==============================] - 0s 294us/sample - loss: 0.2729 - acc: 0.8789 - val_loss: 0.3213 - val_acc: 0.8000\n",
            "Epoch 10/100\n",
            "223/223 [==============================] - 0s 151us/sample - loss: 0.2499 - acc: 0.8879 - val_loss: 0.3386 - val_acc: 0.8000\n",
            "Epoch 11/100\n",
            "223/223 [==============================] - 0s 178us/sample - loss: 0.2507 - acc: 0.8879 - val_loss: 0.3236 - val_acc: 0.8000\n",
            "Epoch 12/100\n",
            "223/223 [==============================] - 0s 166us/sample - loss: 0.2441 - acc: 0.8879 - val_loss: 0.3301 - val_acc: 0.8000\n",
            "Epoch 13/100\n",
            "223/223 [==============================] - 0s 177us/sample - loss: 0.2643 - acc: 0.8879 - val_loss: 0.3553 - val_acc: 0.8000\n",
            "Epoch 14/100\n",
            "223/223 [==============================] - 0s 169us/sample - loss: 0.2540 - acc: 0.9013 - val_loss: 0.3496 - val_acc: 0.8000\n",
            "Epoch 15/100\n",
            "223/223 [==============================] - 0s 170us/sample - loss: 0.2576 - acc: 0.8789 - val_loss: 0.3339 - val_acc: 0.8000\n",
            "Epoch 16/100\n",
            "223/223 [==============================] - 0s 168us/sample - loss: 0.2780 - acc: 0.8565 - val_loss: 0.3248 - val_acc: 0.8000\n",
            "Epoch 17/100\n",
            "223/223 [==============================] - 0s 166us/sample - loss: 0.2885 - acc: 0.8700 - val_loss: 0.3515 - val_acc: 0.8000\n",
            "Epoch 18/100\n",
            "223/223 [==============================] - 0s 214us/sample - loss: 0.2770 - acc: 0.8789 - val_loss: 0.3279 - val_acc: 0.8000\n",
            "Epoch 19/100\n",
            "223/223 [==============================] - 0s 141us/sample - loss: 0.2951 - acc: 0.8789 - val_loss: 0.3363 - val_acc: 0.8000\n",
            "Epoch 20/100\n",
            "223/223 [==============================] - 0s 189us/sample - loss: 0.2540 - acc: 0.8924 - val_loss: 0.3447 - val_acc: 0.8000\n",
            "Epoch 21/100\n",
            "223/223 [==============================] - 0s 182us/sample - loss: 0.2217 - acc: 0.9148 - val_loss: 0.3383 - val_acc: 0.8000\n",
            "Epoch 22/100\n",
            "223/223 [==============================] - 0s 159us/sample - loss: 0.2699 - acc: 0.8655 - val_loss: 0.3336 - val_acc: 0.8000\n",
            "Epoch 23/100\n",
            "223/223 [==============================] - 0s 156us/sample - loss: 0.2574 - acc: 0.9013 - val_loss: 0.3350 - val_acc: 0.8000\n",
            "Epoch 24/100\n",
            "223/223 [==============================] - 0s 167us/sample - loss: 0.2437 - acc: 0.8924 - val_loss: 0.3327 - val_acc: 0.8000\n",
            "Epoch 25/100\n",
            "223/223 [==============================] - 0s 158us/sample - loss: 0.2759 - acc: 0.8700 - val_loss: 0.3297 - val_acc: 0.8400\n",
            "Epoch 26/100\n",
            "223/223 [==============================] - 0s 149us/sample - loss: 0.2194 - acc: 0.8969 - val_loss: 0.3266 - val_acc: 0.8400\n",
            "Epoch 27/100\n",
            "223/223 [==============================] - 0s 304us/sample - loss: 0.2326 - acc: 0.9058 - val_loss: 0.3188 - val_acc: 0.8400\n",
            "Epoch 28/100\n",
            "223/223 [==============================] - 0s 175us/sample - loss: 0.2335 - acc: 0.9103 - val_loss: 0.3228 - val_acc: 0.8400\n",
            "Epoch 29/100\n",
            "223/223 [==============================] - 0s 308us/sample - loss: 0.2081 - acc: 0.9103 - val_loss: 0.3130 - val_acc: 0.8400\n",
            "Epoch 30/100\n",
            "223/223 [==============================] - 0s 163us/sample - loss: 0.2439 - acc: 0.9058 - val_loss: 0.3195 - val_acc: 0.8400\n",
            "Epoch 31/100\n",
            "223/223 [==============================] - 0s 170us/sample - loss: 0.2577 - acc: 0.8969 - val_loss: 0.3484 - val_acc: 0.8000\n",
            "Epoch 32/100\n",
            "223/223 [==============================] - 0s 202us/sample - loss: 0.2206 - acc: 0.8924 - val_loss: 0.3280 - val_acc: 0.8400\n",
            "Epoch 33/100\n",
            "223/223 [==============================] - 0s 187us/sample - loss: 0.2257 - acc: 0.8789 - val_loss: 0.3151 - val_acc: 0.8400\n",
            "Epoch 34/100\n",
            "223/223 [==============================] - 0s 171us/sample - loss: 0.2561 - acc: 0.8924 - val_loss: 0.3244 - val_acc: 0.8400\n",
            "Epoch 35/100\n",
            "223/223 [==============================] - 0s 307us/sample - loss: 0.2319 - acc: 0.8969 - val_loss: 0.3124 - val_acc: 0.8400\n",
            "Epoch 36/100\n",
            "223/223 [==============================] - 0s 159us/sample - loss: 0.3052 - acc: 0.8386 - val_loss: 0.3268 - val_acc: 0.8400\n",
            "Epoch 37/100\n",
            "223/223 [==============================] - 0s 171us/sample - loss: 0.2188 - acc: 0.9058 - val_loss: 0.3366 - val_acc: 0.8400\n",
            "Epoch 38/100\n",
            "223/223 [==============================] - 0s 312us/sample - loss: 0.2557 - acc: 0.8879 - val_loss: 0.3122 - val_acc: 0.8400\n",
            "Epoch 39/100\n",
            "223/223 [==============================] - 0s 192us/sample - loss: 0.2010 - acc: 0.9148 - val_loss: 0.3124 - val_acc: 0.8400\n",
            "Epoch 40/100\n",
            "223/223 [==============================] - 0s 174us/sample - loss: 0.2891 - acc: 0.8744 - val_loss: 0.3337 - val_acc: 0.8400\n",
            "Epoch 41/100\n",
            "223/223 [==============================] - 0s 153us/sample - loss: 0.2484 - acc: 0.8969 - val_loss: 0.3253 - val_acc: 0.8400\n",
            "Epoch 42/100\n",
            "223/223 [==============================] - 0s 154us/sample - loss: 0.2114 - acc: 0.9148 - val_loss: 0.3261 - val_acc: 0.8400\n",
            "Epoch 43/100\n",
            "223/223 [==============================] - 0s 183us/sample - loss: 0.2188 - acc: 0.9058 - val_loss: 0.3282 - val_acc: 0.8400\n",
            "Epoch 44/100\n",
            "223/223 [==============================] - 0s 156us/sample - loss: 0.2609 - acc: 0.8834 - val_loss: 0.3361 - val_acc: 0.8400\n",
            "Epoch 45/100\n",
            "223/223 [==============================] - 0s 154us/sample - loss: 0.2156 - acc: 0.9058 - val_loss: 0.3524 - val_acc: 0.8400\n",
            "Epoch 46/100\n",
            "223/223 [==============================] - 0s 158us/sample - loss: 0.2256 - acc: 0.9148 - val_loss: 0.3652 - val_acc: 0.8000\n",
            "Epoch 47/100\n",
            "223/223 [==============================] - 0s 159us/sample - loss: 0.2110 - acc: 0.9103 - val_loss: 0.3561 - val_acc: 0.8000\n",
            "Epoch 48/100\n",
            "223/223 [==============================] - 0s 162us/sample - loss: 0.2329 - acc: 0.8969 - val_loss: 0.3447 - val_acc: 0.8400\n",
            "Epoch 49/100\n",
            "223/223 [==============================] - 0s 158us/sample - loss: 0.2257 - acc: 0.9238 - val_loss: 0.3389 - val_acc: 0.8400\n",
            "Epoch 50/100\n",
            "223/223 [==============================] - 0s 181us/sample - loss: 0.1907 - acc: 0.9193 - val_loss: 0.3450 - val_acc: 0.8400\n",
            "Epoch 51/100\n",
            "223/223 [==============================] - 0s 184us/sample - loss: 0.2826 - acc: 0.8789 - val_loss: 0.3279 - val_acc: 0.8400\n",
            "Epoch 52/100\n",
            "223/223 [==============================] - 0s 179us/sample - loss: 0.2461 - acc: 0.8655 - val_loss: 0.3225 - val_acc: 0.8400\n",
            "Epoch 53/100\n",
            "223/223 [==============================] - 0s 169us/sample - loss: 0.2161 - acc: 0.9058 - val_loss: 0.3663 - val_acc: 0.8400\n",
            "Epoch 54/100\n",
            "223/223 [==============================] - 0s 169us/sample - loss: 0.2379 - acc: 0.8834 - val_loss: 0.3763 - val_acc: 0.8000\n",
            "Epoch 55/100\n",
            "223/223 [==============================] - 0s 170us/sample - loss: 0.2433 - acc: 0.9058 - val_loss: 0.4082 - val_acc: 0.8400\n",
            "Epoch 56/100\n",
            "223/223 [==============================] - 0s 170us/sample - loss: 0.2471 - acc: 0.8700 - val_loss: 0.4148 - val_acc: 0.8400\n",
            "Epoch 57/100\n",
            "223/223 [==============================] - 0s 167us/sample - loss: 0.2375 - acc: 0.9103 - val_loss: 0.3811 - val_acc: 0.8000\n",
            "Epoch 58/100\n",
            "223/223 [==============================] - 0s 155us/sample - loss: 0.2317 - acc: 0.9013 - val_loss: 0.3688 - val_acc: 0.8000\n",
            "Epoch 59/100\n",
            "223/223 [==============================] - 0s 178us/sample - loss: 0.2552 - acc: 0.8969 - val_loss: 0.3527 - val_acc: 0.8400\n",
            "Epoch 60/100\n",
            "223/223 [==============================] - 0s 181us/sample - loss: 0.2252 - acc: 0.9013 - val_loss: 0.3344 - val_acc: 0.8400\n",
            "Epoch 61/100\n",
            "223/223 [==============================] - 0s 331us/sample - loss: 0.2102 - acc: 0.9103 - val_loss: 0.3073 - val_acc: 0.8400\n",
            "Epoch 62/100\n",
            "223/223 [==============================] - 0s 173us/sample - loss: 0.2271 - acc: 0.9013 - val_loss: 0.3311 - val_acc: 0.8400\n",
            "Epoch 63/100\n",
            "223/223 [==============================] - 0s 185us/sample - loss: 0.2263 - acc: 0.8834 - val_loss: 0.3525 - val_acc: 0.8400\n",
            "Epoch 64/100\n",
            "223/223 [==============================] - 0s 172us/sample - loss: 0.2091 - acc: 0.9103 - val_loss: 0.3349 - val_acc: 0.8400\n",
            "Epoch 65/100\n",
            "223/223 [==============================] - 0s 173us/sample - loss: 0.2557 - acc: 0.8879 - val_loss: 0.3284 - val_acc: 0.8000\n",
            "Epoch 66/100\n",
            "223/223 [==============================] - 0s 184us/sample - loss: 0.2406 - acc: 0.9013 - val_loss: 0.3469 - val_acc: 0.8000\n",
            "Epoch 67/100\n",
            "223/223 [==============================] - 0s 203us/sample - loss: 0.2240 - acc: 0.9058 - val_loss: 0.3647 - val_acc: 0.8000\n",
            "Epoch 68/100\n",
            "223/223 [==============================] - 0s 164us/sample - loss: 0.2145 - acc: 0.9058 - val_loss: 0.3739 - val_acc: 0.8000\n",
            "Epoch 69/100\n",
            "223/223 [==============================] - 0s 172us/sample - loss: 0.2007 - acc: 0.9013 - val_loss: 0.3674 - val_acc: 0.8000\n",
            "Epoch 70/100\n",
            "223/223 [==============================] - 0s 168us/sample - loss: 0.2591 - acc: 0.8924 - val_loss: 0.3855 - val_acc: 0.8000\n",
            "Epoch 71/100\n",
            "223/223 [==============================] - 0s 168us/sample - loss: 0.2076 - acc: 0.8924 - val_loss: 0.3712 - val_acc: 0.8400\n",
            "Epoch 72/100\n",
            "223/223 [==============================] - 0s 167us/sample - loss: 0.2195 - acc: 0.9013 - val_loss: 0.3377 - val_acc: 0.8400\n",
            "Epoch 73/100\n",
            "223/223 [==============================] - 0s 167us/sample - loss: 0.2007 - acc: 0.9103 - val_loss: 0.3754 - val_acc: 0.8400\n",
            "Epoch 74/100\n",
            "223/223 [==============================] - 0s 166us/sample - loss: 0.1987 - acc: 0.9103 - val_loss: 0.4308 - val_acc: 0.8400\n",
            "Epoch 75/100\n",
            "223/223 [==============================] - 0s 188us/sample - loss: 0.1918 - acc: 0.9193 - val_loss: 0.3880 - val_acc: 0.8000\n",
            "Epoch 76/100\n",
            "223/223 [==============================] - 0s 182us/sample - loss: 0.2416 - acc: 0.8879 - val_loss: 0.4199 - val_acc: 0.8000\n",
            "Epoch 77/100\n",
            "223/223 [==============================] - 0s 174us/sample - loss: 0.2238 - acc: 0.8924 - val_loss: 0.4326 - val_acc: 0.8000\n",
            "Epoch 78/100\n",
            "223/223 [==============================] - 0s 175us/sample - loss: 0.2576 - acc: 0.8610 - val_loss: 0.3873 - val_acc: 0.8000\n",
            "Epoch 79/100\n",
            "223/223 [==============================] - 0s 206us/sample - loss: 0.2690 - acc: 0.8834 - val_loss: 0.3971 - val_acc: 0.8000\n",
            "Epoch 80/100\n",
            "223/223 [==============================] - 0s 219us/sample - loss: 0.2185 - acc: 0.9058 - val_loss: 0.3739 - val_acc: 0.8000\n",
            "Epoch 81/100\n",
            "223/223 [==============================] - 0s 167us/sample - loss: 0.2160 - acc: 0.9148 - val_loss: 0.3503 - val_acc: 0.8000\n",
            "Epoch 82/100\n",
            "223/223 [==============================] - 0s 191us/sample - loss: 0.2401 - acc: 0.8969 - val_loss: 0.3308 - val_acc: 0.8000\n",
            "Epoch 83/100\n",
            "223/223 [==============================] - 0s 175us/sample - loss: 0.2576 - acc: 0.8969 - val_loss: 0.3646 - val_acc: 0.8000\n",
            "Epoch 84/100\n",
            "223/223 [==============================] - 0s 183us/sample - loss: 0.2235 - acc: 0.9013 - val_loss: 0.3750 - val_acc: 0.8000\n",
            "Epoch 85/100\n",
            "223/223 [==============================] - 0s 194us/sample - loss: 0.1975 - acc: 0.9058 - val_loss: 0.3785 - val_acc: 0.8000\n",
            "Epoch 86/100\n",
            "223/223 [==============================] - 0s 173us/sample - loss: 0.2156 - acc: 0.8834 - val_loss: 0.4047 - val_acc: 0.8000\n",
            "Epoch 87/100\n",
            "223/223 [==============================] - 0s 176us/sample - loss: 0.2114 - acc: 0.8834 - val_loss: 0.4300 - val_acc: 0.8000\n",
            "Epoch 88/100\n",
            "223/223 [==============================] - 0s 180us/sample - loss: 0.2813 - acc: 0.8879 - val_loss: 0.3639 - val_acc: 0.8000\n",
            "Epoch 89/100\n",
            "223/223 [==============================] - 0s 169us/sample - loss: 0.1914 - acc: 0.9148 - val_loss: 0.3413 - val_acc: 0.8000\n",
            "Epoch 90/100\n",
            "223/223 [==============================] - 0s 182us/sample - loss: 0.2046 - acc: 0.9058 - val_loss: 0.3540 - val_acc: 0.8000\n",
            "Epoch 91/100\n",
            "223/223 [==============================] - 0s 193us/sample - loss: 0.2107 - acc: 0.9327 - val_loss: 0.4028 - val_acc: 0.8400\n",
            "Epoch 92/100\n",
            "223/223 [==============================] - 0s 165us/sample - loss: 0.2591 - acc: 0.8879 - val_loss: 0.3574 - val_acc: 0.8000\n",
            "Epoch 93/100\n",
            "223/223 [==============================] - 0s 168us/sample - loss: 0.2378 - acc: 0.8789 - val_loss: 0.3602 - val_acc: 0.7600\n",
            "Epoch 94/100\n",
            "223/223 [==============================] - 0s 169us/sample - loss: 0.2257 - acc: 0.8924 - val_loss: 0.3629 - val_acc: 0.7600\n",
            "Epoch 95/100\n",
            "223/223 [==============================] - 0s 174us/sample - loss: 0.2129 - acc: 0.8969 - val_loss: 0.3935 - val_acc: 0.8000\n",
            "Epoch 96/100\n",
            "223/223 [==============================] - 0s 176us/sample - loss: 0.2214 - acc: 0.8879 - val_loss: 0.4155 - val_acc: 0.8000\n",
            "Epoch 97/100\n",
            "223/223 [==============================] - 0s 172us/sample - loss: 0.2116 - acc: 0.8655 - val_loss: 0.4019 - val_acc: 0.8400\n",
            "Epoch 98/100\n",
            "223/223 [==============================] - 0s 173us/sample - loss: 0.2242 - acc: 0.8969 - val_loss: 0.3809 - val_acc: 0.8400\n",
            "Epoch 99/100\n",
            "223/223 [==============================] - 0s 172us/sample - loss: 0.2218 - acc: 0.8924 - val_loss: 0.4052 - val_acc: 0.8400\n",
            "Epoch 100/100\n",
            "223/223 [==============================] - 0s 200us/sample - loss: 0.1959 - acc: 0.9103 - val_loss: 0.3796 - val_acc: 0.8400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0bebe39080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5kSWY7VcKa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model = keras.models.load_model(\"bestModel_bio-multi.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnELat9FcKTV",
        "colab_type": "code",
        "outputId": "3fe1dac5-4870-4f5a-9e50-e8b686640a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_loss, test_accuracy = best_model.evaluate(x=xtest_std, y=ytest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 0s 3ms/sample - loss: 0.4435 - acc: 0.8226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdq_OLVxcKRz",
        "colab_type": "code",
        "outputId": "3070b067-f695-4af2-d9b8-aa2b522705c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_loss,test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4435259055706762 0.82258064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z6usXbndhgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}